{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = r'C:\\chromedriver\\chromedriver.exe'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1 Scrape the details of most viewed videos on YouTube from Wikipedia. Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '1.',\n",
       " '2.',\n",
       " '3.',\n",
       " '4.',\n",
       " '5.',\n",
       " '6.',\n",
       " '7.',\n",
       " '8.',\n",
       " '9.',\n",
       " '10.',\n",
       " '11.',\n",
       " '12.',\n",
       " '13.',\n",
       " '14.',\n",
       " '15.',\n",
       " '16.',\n",
       " '17.',\n",
       " '18.',\n",
       " '19.',\n",
       " '20.',\n",
       " '21.',\n",
       " '22.',\n",
       " '23.',\n",
       " '24.',\n",
       " '25.',\n",
       " '26.',\n",
       " '27.',\n",
       " '28.',\n",
       " '29.']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape \n",
    "\n",
    "r = driver.find_elements(By.XPATH,\"//td[1]\")  \n",
    "Rank=[]\n",
    "\n",
    "for i in r[:30]:\n",
    "    Rank.append(i.text)\n",
    "    \n",
    "Rank    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Baby Shark Dance',\n",
       " 'Despacito',\n",
       " 'Johny Johny Yes Papa',\n",
       " 'Shape of You',\n",
       " 'See You Again',\n",
       " 'Wheels on the Bus',\n",
       " 'Uptown Funk',\n",
       " 'Gangnam Style',\n",
       " 'Dame Tu Cosita',\n",
       " 'Axel F',\n",
       " 'Sugar',\n",
       " 'Counting Stars',\n",
       " 'Roar',\n",
       " 'Baa Baa Black Sheep',\n",
       " 'Waka Waka (This Time for Africa)',\n",
       " 'Sorry',\n",
       " 'Lakdi Ki Kathi',\n",
       " 'Thinking Out Loud',\n",
       " 'Dark Horse',\n",
       " 'Humpty the train on a fruits ride',\n",
       " 'Perfect',\n",
       " 'Faded',\n",
       " 'Let Her Go',\n",
       " 'Girls Like You',\n",
       " 'Lean On',\n",
       " 'Bailando',\n",
       " \"Pinkfong Baby Shark - Kids' Songs & Stories\",\n",
       " 'Luis Fonsi',\n",
       " 'Wiz Khalifa',\n",
       " 'Psy']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape Song Na\n",
    "\n",
    "s = driver.find_elements(By.XPATH,\"//td[2]/a\")  #//td[2]/a\n",
    "Song=[]\n",
    "\n",
    "for i in s[:30]:\n",
    "    Song.append(i.text)\n",
    "    \n",
    "Song"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Pinkfong Baby Shark - Kids' Songs & Stories\",\n",
       " 'Luis Fonsi',\n",
       " \"LooLoo Kids - Nursery Rhymes and Children's Songs\",\n",
       " 'Cocomelon - Nursery Rhymes',\n",
       " 'Ed Sheeran',\n",
       " 'Wiz Khalifa',\n",
       " 'Cocomelon - Nursery Rhymes',\n",
       " 'ChuChu TV Nursery Rhymes & Kids Songs',\n",
       " 'Mark Ronson',\n",
       " 'Miroshka TV',\n",
       " 'officialpsy',\n",
       " 'Get Movies',\n",
       " 'Ultra Records',\n",
       " 'Crazy Frog',\n",
       " 'Maroon 5',\n",
       " 'OneRepublic',\n",
       " 'Katy Perry',\n",
       " 'Cocomelon - Nursery Rhymes',\n",
       " 'Shakira',\n",
       " 'Justin Bieber',\n",
       " 'Jingle Toons',\n",
       " 'Ed Sheeran',\n",
       " 'Katy Perry',\n",
       " 'Kiddiestv Hindi - Nursery Rhymes & Kids Songs',\n",
       " 'Ed Sheeran',\n",
       " 'Alan Walker',\n",
       " 'Passenger',\n",
       " 'Maroon 5',\n",
       " 'Major Lazer Official',\n",
       " 'Enrique Iglesias']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape Artist\n",
    "\n",
    "a = driver.find_elements(By.XPATH,\"//td[3]\")  \n",
    "Artist=[]\n",
    "\n",
    "for i in a[:30]:\n",
    "    Artist.append(i.text)\n",
    "    \n",
    "Artist   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['June 17, 2016',\n",
       " 'January 12, 2017',\n",
       " 'October 8, 2016',\n",
       " 'May 2, 2018',\n",
       " 'January 30, 2017',\n",
       " 'April 6, 2015',\n",
       " 'May 24, 2018',\n",
       " 'March 6, 2014',\n",
       " 'November 19, 2014',\n",
       " 'February 27, 2018',\n",
       " 'July 15, 2012',\n",
       " 'January 31, 2012',\n",
       " 'April 5, 2018',\n",
       " 'June 16, 2009',\n",
       " 'January 14, 2015',\n",
       " 'May 31, 2013',\n",
       " 'September 5, 2013',\n",
       " 'June 25, 2018',\n",
       " 'June 4, 2010',\n",
       " 'October 22, 2015',\n",
       " 'June 14, 2018',\n",
       " 'October 7, 2014',\n",
       " 'February 20, 2014',\n",
       " 'January 26, 2018',\n",
       " 'November 9, 2017',\n",
       " 'December 3, 2015',\n",
       " 'July 25, 2012',\n",
       " 'May 31, 2018',\n",
       " 'March 22, 2015',\n",
       " 'April 11, 2014']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape Upload date\n",
    "\n",
    "d = driver.find_elements(By.XPATH,\"//td[5]\")  \n",
    "Date=[]\n",
    "\n",
    "for i in d[:30]:\n",
    "    Date.append(i.text)\n",
    "    \n",
    "Date    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['13.36',\n",
       " '8.26',\n",
       " '6.80',\n",
       " '6.41',\n",
       " '6.08',\n",
       " '6.03',\n",
       " '5.56',\n",
       " '5.48',\n",
       " '5.03',\n",
       " '4.97',\n",
       " '4.90',\n",
       " '4.56',\n",
       " '4.44',\n",
       " '4.06',\n",
       " '3.93',\n",
       " '3.87',\n",
       " '3.87',\n",
       " '3.78',\n",
       " '3.73',\n",
       " '3.71',\n",
       " '3.69',\n",
       " '3.66',\n",
       " '3.59',\n",
       " '3.55',\n",
       " '3.54',\n",
       " '3.51',\n",
       " '3.51',\n",
       " '3.48',\n",
       " '3.46',\n",
       " '3.45']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape Views\n",
    "\n",
    "v = driver.find_elements(By.XPATH,\"//td[4]\")  \n",
    "Views=[]\n",
    "\n",
    "for i in v[:30]:\n",
    "    Views.append(i.text)\n",
    "    \n",
    "Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30 30 30 30 30\n"
     ]
    }
   ],
   "source": [
    "print(len(Rank),len(Song),len(Artist),len(Date),len(Views))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Song Name</th>\n",
       "      <th>Artist Name</th>\n",
       "      <th>Upload Date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td>Baby Shark Dance</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>13.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.</td>\n",
       "      <td>Despacito</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>8.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.</td>\n",
       "      <td>Johny Johny Yes Papa</td>\n",
       "      <td>LooLoo Kids - Nursery Rhymes and Children's Songs</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.</td>\n",
       "      <td>Shape of You</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>6.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.</td>\n",
       "      <td>See You Again</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>6.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5.</td>\n",
       "      <td>Wheels on the Bus</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>6.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6.</td>\n",
       "      <td>Uptown Funk</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>5.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7.</td>\n",
       "      <td>Gangnam Style</td>\n",
       "      <td>ChuChu TV Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>5.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8.</td>\n",
       "      <td>Dame Tu Cosita</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>5.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9.</td>\n",
       "      <td>Axel F</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.</td>\n",
       "      <td>Sugar</td>\n",
       "      <td>officialpsy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.</td>\n",
       "      <td>Counting Stars</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12.</td>\n",
       "      <td>Roar</td>\n",
       "      <td>Ultra Records</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13.</td>\n",
       "      <td>Baa Baa Black Sheep</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>4.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14.</td>\n",
       "      <td>Waka Waka (This Time for Africa)</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15.</td>\n",
       "      <td>Sorry</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16.</td>\n",
       "      <td>Lakdi Ki Kathi</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17.</td>\n",
       "      <td>Thinking Out Loud</td>\n",
       "      <td>Cocomelon - Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18.</td>\n",
       "      <td>Dark Horse</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19.</td>\n",
       "      <td>Humpty the train on a fruits ride</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20.</td>\n",
       "      <td>Perfect</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>June 14, 2018</td>\n",
       "      <td>3.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21.</td>\n",
       "      <td>Faded</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22.</td>\n",
       "      <td>Let Her Go</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23.</td>\n",
       "      <td>Girls Like You</td>\n",
       "      <td>Kiddiestv Hindi - Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24.</td>\n",
       "      <td>Lean On</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25.</td>\n",
       "      <td>Bailando</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26.</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27.</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28.</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>Major Lazer Official</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29.</td>\n",
       "      <td>Psy</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.45</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                    Song Name  \\\n",
       "0                                   Baby Shark Dance   \n",
       "1    1.                                    Despacito   \n",
       "2    2.                         Johny Johny Yes Papa   \n",
       "3    3.                                 Shape of You   \n",
       "4    4.                                See You Again   \n",
       "5    5.                            Wheels on the Bus   \n",
       "6    6.                                  Uptown Funk   \n",
       "7    7.                                Gangnam Style   \n",
       "8    8.                               Dame Tu Cosita   \n",
       "9    9.                                       Axel F   \n",
       "10  10.                                        Sugar   \n",
       "11  11.                               Counting Stars   \n",
       "12  12.                                         Roar   \n",
       "13  13.                          Baa Baa Black Sheep   \n",
       "14  14.             Waka Waka (This Time for Africa)   \n",
       "15  15.                                        Sorry   \n",
       "16  16.                               Lakdi Ki Kathi   \n",
       "17  17.                            Thinking Out Loud   \n",
       "18  18.                                   Dark Horse   \n",
       "19  19.            Humpty the train on a fruits ride   \n",
       "20  20.                                      Perfect   \n",
       "21  21.                                        Faded   \n",
       "22  22.                                   Let Her Go   \n",
       "23  23.                               Girls Like You   \n",
       "24  24.                                      Lean On   \n",
       "25  25.                                     Bailando   \n",
       "26  26.  Pinkfong Baby Shark - Kids' Songs & Stories   \n",
       "27  27.                                   Luis Fonsi   \n",
       "28  28.                                  Wiz Khalifa   \n",
       "29  29.                                          Psy   \n",
       "\n",
       "                                          Artist Name        Upload Date  \\\n",
       "0         Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016   \n",
       "1                                          Luis Fonsi   January 12, 2017   \n",
       "2   LooLoo Kids - Nursery Rhymes and Children's Songs    October 8, 2016   \n",
       "3                          Cocomelon - Nursery Rhymes        May 2, 2018   \n",
       "4                                          Ed Sheeran   January 30, 2017   \n",
       "5                                         Wiz Khalifa      April 6, 2015   \n",
       "6                          Cocomelon - Nursery Rhymes       May 24, 2018   \n",
       "7               ChuChu TV Nursery Rhymes & Kids Songs      March 6, 2014   \n",
       "8                                         Mark Ronson  November 19, 2014   \n",
       "9                                         Miroshka TV  February 27, 2018   \n",
       "10                                        officialpsy      July 15, 2012   \n",
       "11                                         Get Movies   January 31, 2012   \n",
       "12                                      Ultra Records      April 5, 2018   \n",
       "13                                         Crazy Frog      June 16, 2009   \n",
       "14                                           Maroon 5   January 14, 2015   \n",
       "15                                        OneRepublic       May 31, 2013   \n",
       "16                                         Katy Perry  September 5, 2013   \n",
       "17                         Cocomelon - Nursery Rhymes      June 25, 2018   \n",
       "18                                            Shakira       June 4, 2010   \n",
       "19                                      Justin Bieber   October 22, 2015   \n",
       "20                                       Jingle Toons      June 14, 2018   \n",
       "21                                         Ed Sheeran    October 7, 2014   \n",
       "22                                         Katy Perry  February 20, 2014   \n",
       "23      Kiddiestv Hindi - Nursery Rhymes & Kids Songs   January 26, 2018   \n",
       "24                                         Ed Sheeran   November 9, 2017   \n",
       "25                                        Alan Walker   December 3, 2015   \n",
       "26                                          Passenger      July 25, 2012   \n",
       "27                                           Maroon 5       May 31, 2018   \n",
       "28                               Major Lazer Official     March 22, 2015   \n",
       "29                                   Enrique Iglesias     April 11, 2014   \n",
       "\n",
       "    Views  \n",
       "0   13.36  \n",
       "1    8.26  \n",
       "2    6.80  \n",
       "3    6.41  \n",
       "4    6.08  \n",
       "5    6.03  \n",
       "6    5.56  \n",
       "7    5.48  \n",
       "8    5.03  \n",
       "9    4.97  \n",
       "10   4.90  \n",
       "11   4.56  \n",
       "12   4.44  \n",
       "13   4.06  \n",
       "14   3.93  \n",
       "15   3.87  \n",
       "16   3.87  \n",
       "17   3.78  \n",
       "18   3.73  \n",
       "19   3.71  \n",
       "20   3.69  \n",
       "21   3.66  \n",
       "22   3.59  \n",
       "23   3.55  \n",
       "24   3.54  \n",
       "25   3.51  \n",
       "26   3.51  \n",
       "27   3.48  \n",
       "28   3.46  \n",
       "29   3.45  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.DataFrame()\n",
    "\n",
    "df['Rank']=Rank[:30]\n",
    "df['Song Name']=Song[:30]\n",
    "df['Artist Name']=Artist[:30]\n",
    "df['Upload Date']=Date[:30]\n",
    "df['Views']=Views[:30]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2. Scrape the details team Indiaâ€™s international fixtures from bcci.tv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.bcci.tv/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "click=driver.find_element(By.XPATH,\"//*[@id='navigation']/ul[1]/li[2]/a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "click.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ASIA CUP 2023',\n",
       " 'ASIA CUP 2023',\n",
       " '19TH ASIAN GAMES 2023',\n",
       " 'AUSTRALIA TOUR OF INDIA 2023-24',\n",
       " 'AUSTRALIA TOUR OF INDIA 2023-24',\n",
       " 'AUSTRALIA TOUR OF INDIA 2023-24',\n",
       " 'ICC MENS WORLD CUP 2023 WARM-UP MATCHES',\n",
       " '19TH ASIAN GAMES 2023']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape all Match title\n",
    "\n",
    "m = driver.find_elements(By.XPATH,\"//h5[@class='match-tournament-name ng-binding']\")\n",
    "Match=[]\n",
    "\n",
    "for i in m:\n",
    "    Match.append(i.text)\n",
    "    \n",
    "Match    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5th ODI -',\n",
       " 'Final -',\n",
       " '1st T20I -',\n",
       " '1st ODI -',\n",
       " '2nd ODI -',\n",
       " '3rd ODI -',\n",
       " '1st ODI -',\n",
       " '1st T20I -']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape Series\n",
    "\n",
    "s = driver.find_elements(By.XPATH,\"//*[@id='match-card']/div[3]/div/span[1]\")\n",
    "\n",
    "Series=[]\n",
    "\n",
    "for i in s:\n",
    "    Series.append(i.text)\n",
    "    \n",
    "Series    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['R Premadasa International Stadium,',\n",
       " 'R Premadasa International Stadium,',\n",
       " 'Pingfeng Cricket Field,',\n",
       " 'Punjab Cricket Association IS Bindra Stadium,',\n",
       " 'Holkar Cricket Stadium,',\n",
       " 'Saurashtra Cricket Association Stadium,',\n",
       " 'Barsapara Cricket Stadium,',\n",
       " 'Pingfeng Cricket Field,']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape Place name\n",
    "\n",
    "p = driver.find_elements(By.XPATH,\"//span[@class='ng-binding ng-scope']\")\n",
    "\n",
    "Place=[]\n",
    "\n",
    "for i in p:\n",
    "    Place.append(i.text)\n",
    "    \n",
    "Place    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['15 SEP 2023',\n",
       " '17 SEP 2023',\n",
       " '21 SEP 2023',\n",
       " '22 SEP 2023',\n",
       " '24 SEP 2023',\n",
       " '27 SEP 2023',\n",
       " '30 SEP 2023',\n",
       " '3 OCT 2023']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape Date\n",
    "\n",
    "d = driver.find_elements(By.XPATH,\"//div[@class='match-dates ng-binding']\")\n",
    "Date=[]\n",
    "\n",
    "for i in d:\n",
    "    Date.append(i.text)\n",
    "    \n",
    "Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3:00 PM IST',\n",
       " '3:00 PM IST',\n",
       " '6:30 AM IST',\n",
       " '1:30 PM IST',\n",
       " '1:30 PM IST',\n",
       " '1:30 PM IST',\n",
       " '2:00 PM IST',\n",
       " '6:30 AM IST']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape Time\n",
    "\n",
    "t = driver.find_elements(By.XPATH,\"//div[@class='match-time no-margin ng-binding']\")\n",
    "Time=[]\n",
    "\n",
    "for i in t:\n",
    "    Time.append(i.text)\n",
    "    \n",
    "Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8 8 8 8 8\n"
     ]
    }
   ],
   "source": [
    "print(len(Match),len(Series),len(Place),len(Date),len(Time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ASIA CUP 2023</td>\n",
       "      <td>5th ODI -</td>\n",
       "      <td>R Premadasa International Stadium,</td>\n",
       "      <td>15 SEP 2023</td>\n",
       "      <td>3:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASIA CUP 2023</td>\n",
       "      <td>Final -</td>\n",
       "      <td>R Premadasa International Stadium,</td>\n",
       "      <td>17 SEP 2023</td>\n",
       "      <td>3:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19TH ASIAN GAMES 2023</td>\n",
       "      <td>1st T20I -</td>\n",
       "      <td>Pingfeng Cricket Field,</td>\n",
       "      <td>21 SEP 2023</td>\n",
       "      <td>6:30 AM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>1st ODI -</td>\n",
       "      <td>Punjab Cricket Association IS Bindra Stadium,</td>\n",
       "      <td>22 SEP 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>2nd ODI -</td>\n",
       "      <td>Holkar Cricket Stadium,</td>\n",
       "      <td>24 SEP 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AUSTRALIA TOUR OF INDIA 2023-24</td>\n",
       "      <td>3rd ODI -</td>\n",
       "      <td>Saurashtra Cricket Association Stadium,</td>\n",
       "      <td>27 SEP 2023</td>\n",
       "      <td>1:30 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ICC MENS WORLD CUP 2023 WARM-UP MATCHES</td>\n",
       "      <td>1st ODI -</td>\n",
       "      <td>Barsapara Cricket Stadium,</td>\n",
       "      <td>30 SEP 2023</td>\n",
       "      <td>2:00 PM IST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>19TH ASIAN GAMES 2023</td>\n",
       "      <td>1st T20I -</td>\n",
       "      <td>Pingfeng Cricket Field,</td>\n",
       "      <td>3 OCT 2023</td>\n",
       "      <td>6:30 AM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Match      Series  \\\n",
       "0                            ASIA CUP 2023   5th ODI -   \n",
       "1                            ASIA CUP 2023     Final -   \n",
       "2                    19TH ASIAN GAMES 2023  1st T20I -   \n",
       "3          AUSTRALIA TOUR OF INDIA 2023-24   1st ODI -   \n",
       "4          AUSTRALIA TOUR OF INDIA 2023-24   2nd ODI -   \n",
       "5          AUSTRALIA TOUR OF INDIA 2023-24   3rd ODI -   \n",
       "6  ICC MENS WORLD CUP 2023 WARM-UP MATCHES   1st ODI -   \n",
       "7                    19TH ASIAN GAMES 2023  1st T20I -   \n",
       "\n",
       "                                           Place         Date         Time  \n",
       "0             R Premadasa International Stadium,  15 SEP 2023  3:00 PM IST  \n",
       "1             R Premadasa International Stadium,  17 SEP 2023  3:00 PM IST  \n",
       "2                        Pingfeng Cricket Field,  21 SEP 2023  6:30 AM IST  \n",
       "3  Punjab Cricket Association IS Bindra Stadium,  22 SEP 2023  1:30 PM IST  \n",
       "4                        Holkar Cricket Stadium,  24 SEP 2023  1:30 PM IST  \n",
       "5        Saurashtra Cricket Association Stadium,  27 SEP 2023  1:30 PM IST  \n",
       "6                     Barsapara Cricket Stadium,  30 SEP 2023  2:00 PM IST  \n",
       "7                        Pingfeng Cricket Field,   3 OCT 2023  6:30 AM IST  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating DataFrame\n",
    "\n",
    "df=pd.DataFrame()\n",
    "df['Match']=Match[:16]\n",
    "df['Series']=Series[:16]\n",
    "df['Place']=Place[:16]\n",
    "df['Date']=Date[:16]\n",
    "df['Time']=Time[:16]    \n",
    "df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3 Scrape the details of State-wise GDP of India from statisticstime.com. Url = http://statisticstimes.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.statisticstimes.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "btn = driver.find_element(By.XPATH,\"//*[@id='top']/div[2]/div[2]/button\")  \n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = driver.find_element(By.XPATH,\"//*[@id='top']/div[2]/div[2]/div/a[3]\")\n",
    "i.click()                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdp = driver.find_element(By.XPATH,\"//div[2]/ul/li/a\")\n",
    "gdp.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " '10',\n",
       " '11',\n",
       " '12',\n",
       " '13',\n",
       " '14',\n",
       " '15',\n",
       " '16',\n",
       " '17',\n",
       " '18',\n",
       " '19',\n",
       " '20',\n",
       " '21',\n",
       " '22',\n",
       " '23',\n",
       " '24',\n",
       " '25',\n",
       " '26',\n",
       " '27',\n",
       " '28',\n",
       " '29',\n",
       " '30',\n",
       " '31',\n",
       " '32',\n",
       " '33']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape rank\n",
    "\n",
    "r = driver.find_elements(By.XPATH,\"//table[@id='table_id']/tbody/tr/td[1]\")\n",
    "Rank=[]\n",
    "                     \n",
    "for i in r:\n",
    "    Rank.append(i.text)\n",
    "    \n",
    "Rank    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Maharashtra',\n",
       " 'Tamil Nadu',\n",
       " 'Uttar Pradesh',\n",
       " 'Gujarat',\n",
       " 'Karnataka',\n",
       " 'West Bengal',\n",
       " 'Rajasthan',\n",
       " 'Andhra Pradesh',\n",
       " 'Telangana',\n",
       " 'Madhya Pradesh',\n",
       " 'Kerala',\n",
       " 'Delhi',\n",
       " 'Haryana',\n",
       " 'Bihar',\n",
       " 'Punjab',\n",
       " 'Odisha',\n",
       " 'Assam',\n",
       " 'Chhattisgarh',\n",
       " 'Jharkhand',\n",
       " 'Uttarakhand',\n",
       " 'Jammu & Kashmir',\n",
       " 'Himachal Pradesh',\n",
       " 'Goa',\n",
       " 'Tripura',\n",
       " 'Chandigarh',\n",
       " 'Puducherry',\n",
       " 'Meghalaya',\n",
       " 'Sikkim',\n",
       " 'Manipur',\n",
       " 'Nagaland',\n",
       " 'Arunachal Pradesh',\n",
       " 'Mizoram',\n",
       " 'Andaman & Nicobar Islands']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape state Name\n",
    "\n",
    "s = driver.find_elements(By.XPATH,\"//div[5]/div/div/table/tbody/tr/td[2]\")\n",
    "State=[]\n",
    "                     \n",
    "for i in s:\n",
    "    State.append(i.text)\n",
    "    \n",
    "State\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,632,792',\n",
       " '1,630,208',\n",
       " '1,584,764',\n",
       " '1,502,899',\n",
       " '1,493,127',\n",
       " '1,089,898',\n",
       " '942,586',\n",
       " '862,957',\n",
       " '861,031',\n",
       " '809,592',\n",
       " '781,653',\n",
       " '774,870',\n",
       " '734,163',\n",
       " '530,363',\n",
       " '526,376',\n",
       " '487,805',\n",
       " '315,881',\n",
       " '304,063',\n",
       " '297,204',\n",
       " '245,895',\n",
       " '155,956',\n",
       " '153,845',\n",
       " '73,170',\n",
       " '49,845',\n",
       " '42,114',\n",
       " '34,433',\n",
       " '33,481',\n",
       " '28,723',\n",
       " '27,870',\n",
       " '27,283',\n",
       " '24,603',\n",
       " '22,287',\n",
       " '-']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape GSDP(18-19)- at current prices\n",
    "\n",
    "g = driver.find_elements(By.XPATH,\"//div[5]/div/div/table/tbody/tr/td[4]\")\n",
    "GDP18=[]\n",
    "                     \n",
    "for i in g:\n",
    "    GDP18.append(i.text)\n",
    "    \n",
    "GDP18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['-',\n",
       " '1,845,853',\n",
       " '1,687,818',\n",
       " '-',\n",
       " '1,631,977',\n",
       " '1,253,832',\n",
       " '1,020,989',\n",
       " '972,782',\n",
       " '969,604',\n",
       " '906,672',\n",
       " '-',\n",
       " '856,112',\n",
       " '831,610',\n",
       " '611,804',\n",
       " '574,760',\n",
       " '521,275',\n",
       " '-',\n",
       " '329,180',\n",
       " '328,598',\n",
       " '-',\n",
       " '-',\n",
       " '165,472',\n",
       " '80,449',\n",
       " '55,984',\n",
       " '-',\n",
       " '38,253',\n",
       " '36,572',\n",
       " '32,496',\n",
       " '31,790',\n",
       " '-',\n",
       " '-',\n",
       " '26,503',\n",
       " '-']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape GSDP(19-20)- at current prices\n",
    "\n",
    "g1 = driver.find_elements(By.XPATH,\"//div[5]/div/div/table/tbody/tr/td[3]\")\n",
    "GDP19=[]\n",
    "                     \n",
    "for i in g1:\n",
    "    GDP19.append(i.text)\n",
    "    \n",
    "GDP19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['13.94%',\n",
       " '8.63%',\n",
       " '8.39%',\n",
       " '7.96%',\n",
       " '7.91%',\n",
       " '5.77%',\n",
       " '4.99%',\n",
       " '4.57%',\n",
       " '4.56%',\n",
       " '4.29%',\n",
       " '4.14%',\n",
       " '4.10%',\n",
       " '3.89%',\n",
       " '2.81%',\n",
       " '2.79%',\n",
       " '2.58%',\n",
       " '1.67%',\n",
       " '1.61%',\n",
       " '1.57%',\n",
       " '1.30%',\n",
       " '0.83%',\n",
       " '0.81%',\n",
       " '0.39%',\n",
       " '0.26%',\n",
       " '0.22%',\n",
       " '0.18%',\n",
       " '0.18%',\n",
       " '0.15%',\n",
       " '0.15%',\n",
       " '0.14%',\n",
       " '0.13%',\n",
       " '0.12%',\n",
       " '-']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape Share(18-19)\n",
    "\n",
    "s = driver.find_elements(By.XPATH,\"//div[5]/div/div/table/tbody/tr/td[5]\")\n",
    "Share=[]\n",
    "                     \n",
    "for i in s:\n",
    "    Share.append(i.text)\n",
    "    \n",
    "Share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['399.921',\n",
       " '247.629',\n",
       " '240.726',\n",
       " '228.290',\n",
       " '226.806',\n",
       " '165.556',\n",
       " '143.179',\n",
       " '131.083',\n",
       " '130.791',\n",
       " '122.977',\n",
       " '118.733',\n",
       " '117.703',\n",
       " '111.519',\n",
       " '80.562',\n",
       " '79.957',\n",
       " '74.098',\n",
       " '47.982',\n",
       " '46.187',\n",
       " '45.145',\n",
       " '37.351',\n",
       " '23.690',\n",
       " '23.369',\n",
       " '11.115',\n",
       " '7.571',\n",
       " '6.397',\n",
       " '5.230',\n",
       " '5.086',\n",
       " '4.363',\n",
       " '4.233',\n",
       " '4.144',\n",
       " '3.737',\n",
       " '3.385',\n",
       " '-']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape GDP($ billion)\n",
    "\n",
    "b = driver.find_elements(By.XPATH,\"//div[5]/div/div/table/tbody/tr/td[6]\")\n",
    "GDP=[]\n",
    "                     \n",
    "for i in b:\n",
    "    GDP.append(i.text)\n",
    "    \n",
    "GDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 33 33 33 33 33\n"
     ]
    }
   ],
   "source": [
    "print(len(Rank),len(State),len(GDP18),len(GDP19),len(Share),len(GDP))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GDP18</th>\n",
       "      <th>GDP19</th>\n",
       "      <th>Share</th>\n",
       "      <th>GDP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>-</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>-</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>942,586</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>862,957</td>\n",
       "      <td>972,782</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>861,031</td>\n",
       "      <td>969,604</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>809,592</td>\n",
       "      <td>906,672</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>781,653</td>\n",
       "      <td>-</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>774,870</td>\n",
       "      <td>856,112</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>734,163</td>\n",
       "      <td>831,610</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>530,363</td>\n",
       "      <td>611,804</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>526,376</td>\n",
       "      <td>574,760</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>487,805</td>\n",
       "      <td>521,275</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>315,881</td>\n",
       "      <td>-</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>304,063</td>\n",
       "      <td>329,180</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>297,204</td>\n",
       "      <td>328,598</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>245,895</td>\n",
       "      <td>-</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>155,956</td>\n",
       "      <td>-</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>153,845</td>\n",
       "      <td>165,472</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>73,170</td>\n",
       "      <td>80,449</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>49,845</td>\n",
       "      <td>55,984</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>42,114</td>\n",
       "      <td>-</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>34,433</td>\n",
       "      <td>38,253</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>33,481</td>\n",
       "      <td>36,572</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>28,723</td>\n",
       "      <td>32,496</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>27,870</td>\n",
       "      <td>31,790</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>27,283</td>\n",
       "      <td>-</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>24,603</td>\n",
       "      <td>-</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>22,287</td>\n",
       "      <td>26,503</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State      GDP18      GDP19   Share      GDP\n",
       "0     1                Maharashtra  2,632,792          -  13.94%  399.921\n",
       "1     2                 Tamil Nadu  1,630,208  1,845,853   8.63%  247.629\n",
       "2     3              Uttar Pradesh  1,584,764  1,687,818   8.39%  240.726\n",
       "3     4                    Gujarat  1,502,899          -   7.96%  228.290\n",
       "4     5                  Karnataka  1,493,127  1,631,977   7.91%  226.806\n",
       "5     6                West Bengal  1,089,898  1,253,832   5.77%  165.556\n",
       "6     7                  Rajasthan    942,586  1,020,989   4.99%  143.179\n",
       "7     8             Andhra Pradesh    862,957    972,782   4.57%  131.083\n",
       "8     9                  Telangana    861,031    969,604   4.56%  130.791\n",
       "9    10             Madhya Pradesh    809,592    906,672   4.29%  122.977\n",
       "10   11                     Kerala    781,653          -   4.14%  118.733\n",
       "11   12                      Delhi    774,870    856,112   4.10%  117.703\n",
       "12   13                    Haryana    734,163    831,610   3.89%  111.519\n",
       "13   14                      Bihar    530,363    611,804   2.81%   80.562\n",
       "14   15                     Punjab    526,376    574,760   2.79%   79.957\n",
       "15   16                     Odisha    487,805    521,275   2.58%   74.098\n",
       "16   17                      Assam    315,881          -   1.67%   47.982\n",
       "17   18               Chhattisgarh    304,063    329,180   1.61%   46.187\n",
       "18   19                  Jharkhand    297,204    328,598   1.57%   45.145\n",
       "19   20                Uttarakhand    245,895          -   1.30%   37.351\n",
       "20   21            Jammu & Kashmir    155,956          -   0.83%   23.690\n",
       "21   22           Himachal Pradesh    153,845    165,472   0.81%   23.369\n",
       "22   23                        Goa     73,170     80,449   0.39%   11.115\n",
       "23   24                    Tripura     49,845     55,984   0.26%    7.571\n",
       "24   25                 Chandigarh     42,114          -   0.22%    6.397\n",
       "25   26                 Puducherry     34,433     38,253   0.18%    5.230\n",
       "26   27                  Meghalaya     33,481     36,572   0.18%    5.086\n",
       "27   28                     Sikkim     28,723     32,496   0.15%    4.363\n",
       "28   29                    Manipur     27,870     31,790   0.15%    4.233\n",
       "29   30                   Nagaland     27,283          -   0.14%    4.144\n",
       "30   31          Arunachal Pradesh     24,603          -   0.13%    3.737\n",
       "31   32                    Mizoram     22,287     26,503   0.12%    3.385\n",
       "32   33  Andaman & Nicobar Islands          -          -       -        -"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.DataFrame()\n",
    "\n",
    "df['Rank']=Rank[:33]\n",
    "df['State']=State[:33]\n",
    "df['GDP18']=GDP18[:33]\n",
    "df['GDP19']=GDP19[:33]\n",
    "df['Share']=Share[:33]\n",
    "df['GDP']=GDP[:33]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4 Scrape the details of trending repositories on Github.com.Url = https://github.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://github.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.XPATH,\"//span[@class='flex-1']\")\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert=driver.find_element(By.XPATH,\"//input[@id='query-builder-test']\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "insert.send_keys(\"Trending Repository\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "btn = driver.find_element(By.XPATH,\"//span[@class='ActionListItem-descriptionWrap']\")\n",
    "btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['QasimWani/LeetHub',\n",
       " 'vitalets/github-trending-repos',\n",
       " 'mbadry1/Trending-Deep-Learning',\n",
       " 'laowch/GithubTrends',\n",
       " 'ophobe/trending',\n",
       " 'zhuowenli/githuber',\n",
       " 'andygrunwald/TrendingGithub',\n",
       " 'andygrunwald/go-trending',\n",
       " 'karlrupp/microprocessor-trend-data',\n",
       " 'ecrmnn/trending-github']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape Repository titles\n",
    "\n",
    "r = driver.find_elements(By.XPATH,\"//span[@class='Text-sc-17v1xeu-0 qaOIC search-match']\")\n",
    "\n",
    "Repository=[]\n",
    "for i in r:\n",
    "    Repository.append(i.text)\n",
    "        \n",
    "        \n",
    "Repository    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//a[8]\"}\n  (Session info: chrome=116.0.5845.190); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF7900852A2+57122]\n\t(No symbol) [0x00007FF78FFFEA92]\n\t(No symbol) [0x00007FF78FECE3AB]\n\t(No symbol) [0x00007FF78FF07D3E]\n\t(No symbol) [0x00007FF78FF07E2C]\n\t(No symbol) [0x00007FF78FF40B67]\n\t(No symbol) [0x00007FF78FF2701F]\n\t(No symbol) [0x00007FF78FF3EB82]\n\t(No symbol) [0x00007FF78FF26DB3]\n\t(No symbol) [0x00007FF78FEFD2B1]\n\t(No symbol) [0x00007FF78FEFE494]\n\tGetHandleVerifier [0x00007FF79032EF82+2849794]\n\tGetHandleVerifier [0x00007FF790381D24+3189156]\n\tGetHandleVerifier [0x00007FF79037ACAF+3160367]\n\tGetHandleVerifier [0x00007FF790116D06+653702]\n\t(No symbol) [0x00007FF79000A208]\n\t(No symbol) [0x00007FF7900062C4]\n\t(No symbol) [0x00007FF7900063F6]\n\t(No symbol) [0x00007FF78FFF67A3]\n\tBaseThreadInitThunk [0x00007FFCF6E47344+20]\n\tRtlUserThreadStart [0x00007FFCF8CE26B1+33]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-0253b2d6fc1b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m           \u001b[0mRepository\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mnxtbtn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"//a[8]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mnxtbtn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    737\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf'[name=\"{value}\"]'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 739\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFIND_ELEMENT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m\"using\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"value\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    740\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    741\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mWebElement\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    343\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    344\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 345\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    346\u001b[0m             \u001b[0mresponse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_unwrap_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    347\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"alert\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"text\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    228\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 229\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//a[8]\"}\n  (Session info: chrome=116.0.5845.190); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF7900852A2+57122]\n\t(No symbol) [0x00007FF78FFFEA92]\n\t(No symbol) [0x00007FF78FECE3AB]\n\t(No symbol) [0x00007FF78FF07D3E]\n\t(No symbol) [0x00007FF78FF07E2C]\n\t(No symbol) [0x00007FF78FF40B67]\n\t(No symbol) [0x00007FF78FF2701F]\n\t(No symbol) [0x00007FF78FF3EB82]\n\t(No symbol) [0x00007FF78FF26DB3]\n\t(No symbol) [0x00007FF78FEFD2B1]\n\t(No symbol) [0x00007FF78FEFE494]\n\tGetHandleVerifier [0x00007FF79032EF82+2849794]\n\tGetHandleVerifier [0x00007FF790381D24+3189156]\n\tGetHandleVerifier [0x00007FF79037ACAF+3160367]\n\tGetHandleVerifier [0x00007FF790116D06+653702]\n\t(No symbol) [0x00007FF79000A208]\n\t(No symbol) [0x00007FF7900062C4]\n\t(No symbol) [0x00007FF7900063F6]\n\t(No symbol) [0x00007FF78FFF67A3]\n\tBaseThreadInitThunk [0x00007FFCF6E47344+20]\n\tRtlUserThreadStart [0x00007FFCF8CE26B1+33]\n"
     ]
    }
   ],
   "source": [
    "start=0\n",
    "end=10\n",
    "Repository=[]\n",
    "for page in range(start,end):\n",
    "    r = driver.find_elements(By.XPATH,\"//span[@class='Text-sc-17v1xeu-0 qaOIC search-match']\")\n",
    "    for i in r:\n",
    "          Repository.append(i.text)\n",
    "    nxtbtn = driver.find_element(By.XPATH,\"//a[8]\")\n",
    "    nxtbtn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['â— This is a read-only mirror of the CRAN R package repository. sta â€” Seasonal Trend Analysis for Time Series Imagery in R',\n",
       " 'Welcome to my data analysis portfolio! This repository showcases a collection of my data analysis projects, where I explore various datasâ€¦',\n",
       " 'This repository contains a Power BI solution for AtliQ hardware, enabling comprehensive analysis of sales trends, informed decision-makinâ€¦',\n",
       " 'Technical Analysis of Currency Pairs in Forex environment. This repository is will be part of future implementation of AI & ML algorithmsâ€¦',\n",
       " 'â— This is a read-only mirror of the CRAN R package repository. CATTexact â€” Computation of the p-Value for the Exact Conditional Cochran-Aâ€¦',\n",
       " 'This repository holds the code for CSSS 510 MLE final Project. My code takes care of data pipeline and propensity trend examination part â€¦',\n",
       " 'This repository contains code and information on how the TrEnD_Lab conducts exploratory metabarcoding data analysis. R and shell are usedâ€¦',\n",
       " 'this repository write the thing that I learn today. I promise that I write it everyday. I focus on time series theory and hadoop ecosystem â€¦',\n",
       " 'This repository is a personal project to look for trends in Covid-19. The numbers are sourced from publicly available data.',\n",
       " 'This repository shows how Python can be used to see the moving average trends for Covid-19 deaths, testing, and hospitalizations in Marylâ€¦']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape Repository description\n",
    "\n",
    "d= driver.find_elements(By.XPATH,\"//div[4]/div/div/div/div/div/div/span\")\n",
    "\n",
    "\n",
    "Description=[]\n",
    "\n",
    "for i in d:\n",
    "    Description.append(i.text)\n",
    "        \n",
    "        \n",
    "Description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape Contribution Count\n",
    "\n",
    "c= driver.find_elements(By.XPATH,\"//div[4]/div/div/div/div/div/div/span\")\n",
    "\n",
    "\n",
    "Contribution=[]\n",
    "\n",
    "for i in c:\n",
    "    Contribution.append(i.text)\n",
    "        \n",
    "        \n",
    "Contribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '',\n",
       " '1.6k',\n",
       " '',\n",
       " '',\n",
       " '4k',\n",
       " '',\n",
       " '',\n",
       " '128k',\n",
       " '',\n",
       " '',\n",
       " '174',\n",
       " '',\n",
       " '',\n",
       " '4',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'R',\n",
       " '0',\n",
       " 'Updated on Mar 15',\n",
       " 'on Mar 15',\n",
       " '0',\n",
       " 'Updated on Jul 15',\n",
       " 'on Jul 15',\n",
       " '1',\n",
       " 'Updated on Jun 5',\n",
       " 'on Jun 5',\n",
       " '0',\n",
       " 'Updated on Aug 4',\n",
       " 'on Aug 4',\n",
       " 'R',\n",
       " '0',\n",
       " 'Updated on Jul 2, 2020',\n",
       " 'on Jul 2, 2020',\n",
       " 'R',\n",
       " '0',\n",
       " 'Updated on Mar 23, 2017',\n",
       " 'on Mar 23, 2017',\n",
       " 'HTML',\n",
       " '0',\n",
       " 'Updated on Nov 22, 2018',\n",
       " 'on Nov 22, 2018',\n",
       " '0',\n",
       " 'Updated on Sep 17, 2020',\n",
       " 'on Sep 17, 2020',\n",
       " 'Jupyter Notebook',\n",
       " '0',\n",
       " 'Updated on Dec 24, 2020',\n",
       " 'on Dec 24, 2020',\n",
       " 'Jupyter Notebook',\n",
       " '0',\n",
       " 'Updated on Dec 4, 2020',\n",
       " 'on Dec 4, 2020',\n",
       " '',\n",
       " 'Press the / key to activate the search input again and adjust your query.']"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape Language Used\n",
    "\n",
    "l= driver.find_elements(By.XPATH,\"//span[@class='Text-sc-17v1xeu-0 gPDEWA']\")\n",
    "\n",
    "\n",
    "Language=[]\n",
    "\n",
    "for i in l:\n",
    "    Language.append(i.text)\n",
    "        \n",
    "        \n",
    "Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 5 Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/ You have to find the following details:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.billboard.com/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Click on Charts link\n",
    "\n",
    "c = driver.find_element(By.XPATH,\"(//a[contains(text(),'Charts')])[2]\")\n",
    "\n",
    "c.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = driver.find_element(By.XPATH,\"//a[contains(text(),'Billboard Hot 100')]\")\n",
    "b.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I Remember Everything',\n",
       " 'Fast Car',\n",
       " 'Cruel Summer',\n",
       " 'Last Night',\n",
       " 'Dance The Night',\n",
       " 'Snooze',\n",
       " 'Fukumean',\n",
       " 'Vampire',\n",
       " 'Calm Down',\n",
       " 'Rich Men North Of Richmond',\n",
       " 'Barbie World',\n",
       " 'Flowers',\n",
       " 'All My Life',\n",
       " 'Religiously',\n",
       " 'Used To Be Young',\n",
       " 'Hey Driver',\n",
       " 'Need A Favor',\n",
       " \"Thinkin' Bout Me\",\n",
       " 'Anti-Hero',\n",
       " 'Kill Bill',\n",
       " 'What Was I Made For?',\n",
       " 'Last Time I Saw You',\n",
       " 'Karma',\n",
       " \"Creepin'\",\n",
       " 'Bad Idea Right?',\n",
       " 'Meltdown',\n",
       " 'Dial Drunk',\n",
       " 'Tourniquet',\n",
       " 'Try That In A Small Town',\n",
       " 'Qlona',\n",
       " 'Love You Anyway',\n",
       " 'Watermelon Moonshine',\n",
       " 'I Know ?',\n",
       " 'Spotless',\n",
       " 'Bury Me In Georgia',\n",
       " 'Seven',\n",
       " 'Margaritaville',\n",
       " 'Single Soon',\n",
       " 'East Side Of Sorrow',\n",
       " 'What It Is (Block Boy)',\n",
       " 'Daylight',\n",
       " 'Mi Ex Tenia Razon',\n",
       " 'LaLa',\n",
       " 'Cupid',\n",
       " 'Demons',\n",
       " 'Lady Gaga',\n",
       " \"Fear And Friday's\",\n",
       " 'El Dorado',\n",
       " 'Telekinesis',\n",
       " 'Peaches & Eggplants',\n",
       " 'Ticking',\n",
       " \"Summertime's Close\",\n",
       " 'FE!N',\n",
       " 'Overtime',\n",
       " 'Come See Me',\n",
       " 'White Horse',\n",
       " 'Good Good',\n",
       " 'Truck Bed',\n",
       " 'Deli',\n",
       " 'Que Onda',\n",
       " 'Standing Room Only',\n",
       " 'Smaller Acts',\n",
       " 'Everything I Love',\n",
       " 'In Your Love',\n",
       " 'Popular',\n",
       " 'SkeeYee',\n",
       " 'Put It On Da Floor Again',\n",
       " 'Holy Roller',\n",
       " 'Sabor Fresa',\n",
       " 'Tulum',\n",
       " 'Where She Goes',\n",
       " \"Angels Don't Always Have Wings\",\n",
       " 'K-POP',\n",
       " 'Johnny Dang',\n",
       " 'Oh U Went',\n",
       " 'Dawns',\n",
       " \"Jake's Piano - Long Island\",\n",
       " 'Save Me',\n",
       " 'Oklahoma Smoke Show',\n",
       " 'Lose Control',\n",
       " 'Tradesman',\n",
       " 'Shake Sumn',\n",
       " 'Keep Going Up!',\n",
       " 'Area Codes',\n",
       " \"Sittin' On Top Of The World\",\n",
       " 'Pretty Little Poison',\n",
       " 'Oklahoman Son',\n",
       " 'TQM',\n",
       " 'See You Again',\n",
       " 'Amargura',\n",
       " 'Girl In Mine',\n",
       " 'El Amor de Su Vida',\n",
       " 'Summer Too Hot',\n",
       " 'Rubicon',\n",
       " 'Stand By Me',\n",
       " 'Call Your Friends',\n",
       " 'Your Heart Or Mine',\n",
       " 'Primera Cita',\n",
       " 'S91']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape Song name\n",
    "\n",
    "s = driver.find_elements(By.XPATH,\"//h3[@class='c-title  a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 lrv-u-font-size-18@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-330 u-max-width-230@tablet-only']\")   \n",
    "Song=[]\n",
    "\n",
    "for i in s:\n",
    "    Song.append(i.text)\n",
    "    \n",
    "Song    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Zach Bryan Featuring Kacey Musgraves',\n",
       " 'Luke Combs',\n",
       " 'Taylor Swift',\n",
       " 'Morgan Wallen',\n",
       " 'Dua Lipa',\n",
       " 'SZA',\n",
       " 'Gunna',\n",
       " 'Olivia Rodrigo',\n",
       " 'Rema & Selena Gomez',\n",
       " 'Oliver Anthony Music',\n",
       " 'Nicki Minaj & Ice Spice With Aqua',\n",
       " 'Miley Cyrus',\n",
       " 'Lil Durk Featuring J. Cole',\n",
       " 'Bailey Zimmerman',\n",
       " 'Miley Cyrus',\n",
       " 'Zach Bryan Featuring The War And Treaty',\n",
       " 'Jelly Roll',\n",
       " 'Morgan Wallen',\n",
       " 'Taylor Swift',\n",
       " 'SZA',\n",
       " 'Billie Eilish',\n",
       " 'Nicki Minaj',\n",
       " 'Taylor Swift Featuring Ice Spice',\n",
       " 'Metro Boomin, The Weeknd & 21 Savage',\n",
       " 'Olivia Rodrigo',\n",
       " 'Travis Scott Featuring Drake',\n",
       " 'Noah Kahan With Post Malone',\n",
       " 'Zach Bryan',\n",
       " 'Jason Aldean',\n",
       " 'Karol G & Peso Pluma',\n",
       " 'Luke Combs',\n",
       " 'Lainey Wilson',\n",
       " 'Travis Scott',\n",
       " 'Zach Bryan Featuring The Lumineers',\n",
       " 'Kane Brown',\n",
       " 'Jung Kook Featuring Latto',\n",
       " 'Jimmy Buffett',\n",
       " 'Selena Gomez',\n",
       " 'Zach Bryan',\n",
       " 'Doechii Featuring Kodak Black',\n",
       " 'David Kushner',\n",
       " 'Karol G',\n",
       " 'Myke Towers',\n",
       " 'Fifty Fifty',\n",
       " 'Doja Cat',\n",
       " 'Peso Pluma, Gabito Ballesteros & Junior H',\n",
       " 'Zach Bryan',\n",
       " 'Zach Bryan',\n",
       " 'Travis Scott Featuring SZA & Future',\n",
       " 'Young Nudy Featuring 21 Savage',\n",
       " 'Zach Bryan',\n",
       " 'Zach Bryan',\n",
       " 'Travis Scott Featuring Playboi Carti',\n",
       " 'Zach Bryan',\n",
       " 'Rod Wave',\n",
       " 'Chris Stapleton',\n",
       " 'Usher, Summer Walker & 21 Savage',\n",
       " 'HARDY',\n",
       " 'Ice Spice',\n",
       " 'Calle 24 x Chino Pacas x Fuerza Regida',\n",
       " 'Tim McGraw',\n",
       " 'Zach Bryan',\n",
       " 'Morgan Wallen',\n",
       " 'Tyler Childers',\n",
       " 'The Weeknd, Playboi Carti & Madonna',\n",
       " 'Sexyy Red',\n",
       " 'Latto Featuring Cardi B',\n",
       " 'Zach Bryan Featuring Sierra Ferrell',\n",
       " 'Fuerza Regida',\n",
       " 'Peso Pluma & Grupo Frontera',\n",
       " 'Bad Bunny',\n",
       " 'Thomas Rhett',\n",
       " 'Travis Scott, Bad Bunny & The Weeknd',\n",
       " 'That Mexican OT, Paul Wall & DRODi',\n",
       " 'Young Thug Featuring Drake',\n",
       " 'Zach Bryan Featuring Maggie Rogers',\n",
       " 'Zach Bryan',\n",
       " 'Jelly Roll With Lainey Wilson',\n",
       " 'Zach Bryan',\n",
       " 'Teddy Swims',\n",
       " 'Zach Bryan',\n",
       " 'DaBaby',\n",
       " 'Timbaland, Nelly Furtado & Justin Timberlake',\n",
       " 'Kaliii',\n",
       " 'Burna Boy',\n",
       " 'Warren Zeiders',\n",
       " 'Zach Bryan',\n",
       " 'Fuerza Regida',\n",
       " 'Tyler, The Creator Featuring Kali Uchis',\n",
       " 'Karol G',\n",
       " 'Parmalee',\n",
       " 'Grupo Frontera & Grupo Firme',\n",
       " 'Chris Brown',\n",
       " 'Peso Pluma',\n",
       " 'Lil Durk Featuring Morgan Wallen',\n",
       " 'Rod Wave',\n",
       " 'Jon Pardi',\n",
       " 'Carin Leon',\n",
       " 'Karol G']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrpae Artist name\n",
    "\n",
    "a = driver.find_elements(By.XPATH,\"//span[@class='c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only']\")\n",
    "\n",
    "Artist=[]\n",
    "\n",
    "for i in a:\n",
    "    Artist.append(i.text)\n",
    "    \n",
    "Artist    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '2',\n",
       " '',\n",
       " '5',\n",
       " '',\n",
       " '4',\n",
       " '',\n",
       " '9',\n",
       " '',\n",
       " '7',\n",
       " '',\n",
       " '10',\n",
       " '',\n",
       " '12',\n",
       " '',\n",
       " '11',\n",
       " '',\n",
       " '6',\n",
       " '',\n",
       " '13',\n",
       " '',\n",
       " '15',\n",
       " '',\n",
       " '16',\n",
       " '',\n",
       " '21',\n",
       " '',\n",
       " '8',\n",
       " '',\n",
       " '14',\n",
       " '',\n",
       " '26',\n",
       " '',\n",
       " '34',\n",
       " '',\n",
       " '32',\n",
       " '',\n",
       " '27',\n",
       " '',\n",
       " '30',\n",
       " '',\n",
       " '-',\n",
       " '',\n",
       " '25',\n",
       " '',\n",
       " '33',\n",
       " '',\n",
       " '35',\n",
       " '',\n",
       " '36',\n",
       " '',\n",
       " '42',\n",
       " '',\n",
       " '20',\n",
       " '',\n",
       " '45',\n",
       " '',\n",
       " '43',\n",
       " '',\n",
       " '40',\n",
       " '',\n",
       " '46',\n",
       " '',\n",
       " '49',\n",
       " '',\n",
       " '17',\n",
       " '',\n",
       " '51',\n",
       " '',\n",
       " '28',\n",
       " '',\n",
       " '-',\n",
       " '',\n",
       " '19',\n",
       " '',\n",
       " '18',\n",
       " '',\n",
       " '53',\n",
       " '',\n",
       " '52',\n",
       " '',\n",
       " '50',\n",
       " '',\n",
       " '54',\n",
       " '',\n",
       " '48',\n",
       " '',\n",
       " '-',\n",
       " '',\n",
       " '56',\n",
       " '',\n",
       " '24',\n",
       " '',\n",
       " '31',\n",
       " '',\n",
       " '55']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrpae Last week rank\n",
    "\n",
    "last = driver.find_elements(By.XPATH,\"//li[4]/span\")\n",
    "Last_Week_Rank=[]\n",
    "\n",
    "for i in last[:99]:\n",
    "    Last_Week_Rank.append(i.text)\n",
    "    \n",
    "Last_Week_Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '2',\n",
       " '',\n",
       " '3',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '6',\n",
       " '',\n",
       " '7',\n",
       " '',\n",
       " '4',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '3',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '7',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '2',\n",
       " '',\n",
       " '14',\n",
       " '',\n",
       " '8',\n",
       " '',\n",
       " '14',\n",
       " '',\n",
       " '14',\n",
       " '',\n",
       " '9',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '14',\n",
       " '',\n",
       " '23',\n",
       " '',\n",
       " '2',\n",
       " '',\n",
       " '3',\n",
       " '',\n",
       " '10',\n",
       " '',\n",
       " '3',\n",
       " '',\n",
       " '25',\n",
       " '',\n",
       " '20',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '28',\n",
       " '',\n",
       " '15',\n",
       " '',\n",
       " '33',\n",
       " '',\n",
       " '11',\n",
       " '',\n",
       " '17',\n",
       " '',\n",
       " '34',\n",
       " '',\n",
       " '1',\n",
       " '',\n",
       " '8',\n",
       " '',\n",
       " '19',\n",
       " '',\n",
       " '18',\n",
       " '',\n",
       " '41',\n",
       " '',\n",
       " '40',\n",
       " '',\n",
       " '22',\n",
       " '',\n",
       " '43',\n",
       " '',\n",
       " '17',\n",
       " '',\n",
       " '46',\n",
       " '',\n",
       " '35',\n",
       " '',\n",
       " '24',\n",
       " '',\n",
       " '31',\n",
       " '',\n",
       " '26']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrpae Peak rank\n",
    "\n",
    "r = driver.find_elements(By.XPATH,\"//li[5]/span\")\n",
    "Peak_Rank=[]\n",
    "\n",
    "for i in r[:99]:\n",
    "    Peak_Rank.append(i.text)\n",
    "    \n",
    "Peak_Rank    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5',\n",
       " '2',\n",
       " '24',\n",
       " '18',\n",
       " '32',\n",
       " '15',\n",
       " '39',\n",
       " '12',\n",
       " '10',\n",
       " '53',\n",
       " '4',\n",
       " '11',\n",
       " '34',\n",
       " '17',\n",
       " '18',\n",
       " '2',\n",
       " '2',\n",
       " '23',\n",
       " '27',\n",
       " '46',\n",
       " '39',\n",
       " '8',\n",
       " '1',\n",
       " '26',\n",
       " '40',\n",
       " '4',\n",
       " '6',\n",
       " '12',\n",
       " '2',\n",
       " '8',\n",
       " '4',\n",
       " '30',\n",
       " '11',\n",
       " '6',\n",
       " '2',\n",
       " '17',\n",
       " '8',\n",
       " '23',\n",
       " '2',\n",
       " '2',\n",
       " '18',\n",
       " '21',\n",
       " '4',\n",
       " '9',\n",
       " '25',\n",
       " '1',\n",
       " '11',\n",
       " '2',\n",
       " '2',\n",
       " '6',\n",
       " '14',\n",
       " '2',\n",
       " '2',\n",
       " '6',\n",
       " '2',\n",
       " '1',\n",
       " '7',\n",
       " '4',\n",
       " '12',\n",
       " '7',\n",
       " '1',\n",
       " '3',\n",
       " '2',\n",
       " '28',\n",
       " '6',\n",
       " '14',\n",
       " '1',\n",
       " '14',\n",
       " '2',\n",
       " '11',\n",
       " '10',\n",
       " '16',\n",
       " '7',\n",
       " '7',\n",
       " '8',\n",
       " '11',\n",
       " '19',\n",
       " '2',\n",
       " '12',\n",
       " '7',\n",
       " '4',\n",
       " '2',\n",
       " '16',\n",
       " '1',\n",
       " '18',\n",
       " '2',\n",
       " '4',\n",
       " '2',\n",
       " '16',\n",
       " '20',\n",
       " '4',\n",
       " '6',\n",
       " '3',\n",
       " '3',\n",
       " '10',\n",
       " '15',\n",
       " '3',\n",
       " '17',\n",
       " '2']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrpae Weeks on board\n",
    "\n",
    "b = driver.find_elements(By.XPATH,\"//li[6]/span\")\n",
    "Board=[]\n",
    "\n",
    "for i in b[:99]:\n",
    "    Board.append(i.text)\n",
    "    \n",
    "Board "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 99 99 99 99\n"
     ]
    }
   ],
   "source": [
    "print(len(Song),len(Artist),len(Last_Week_Rank),len(Peak_Rank),len(Board))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song name</th>\n",
       "      <th>Artist Name</th>\n",
       "      <th>Last Week Rank</th>\n",
       "      <th>Peak Rank</th>\n",
       "      <th>Weeks on board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I Remember Everything</td>\n",
       "      <td>Zach Bryan Featuring Kacey Musgraves</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fast Car</td>\n",
       "      <td>Luke Combs</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cruel Summer</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Last Night</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dance The Night</td>\n",
       "      <td>Dua Lipa</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Snooze</td>\n",
       "      <td>SZA</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Fukumean</td>\n",
       "      <td>Gunna</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Vampire</td>\n",
       "      <td>Olivia Rodrigo</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Calm Down</td>\n",
       "      <td>Rema &amp; Selena Gomez</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Rich Men North Of Richmond</td>\n",
       "      <td>Oliver Anthony Music</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Barbie World</td>\n",
       "      <td>Nicki Minaj &amp; Ice Spice With Aqua</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Flowers</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>All My Life</td>\n",
       "      <td>Lil Durk Featuring J. Cole</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Religiously</td>\n",
       "      <td>Bailey Zimmerman</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Used To Be Young</td>\n",
       "      <td>Miley Cyrus</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Hey Driver</td>\n",
       "      <td>Zach Bryan Featuring The War And Treaty</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Need A Favor</td>\n",
       "      <td>Jelly Roll</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Thinkin' Bout Me</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Anti-Hero</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Kill Bill</td>\n",
       "      <td>SZA</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>What Was I Made For?</td>\n",
       "      <td>Billie Eilish</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Last Time I Saw You</td>\n",
       "      <td>Nicki Minaj</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Karma</td>\n",
       "      <td>Taylor Swift Featuring Ice Spice</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Creepin'</td>\n",
       "      <td>Metro Boomin, The Weeknd &amp; 21 Savage</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Bad Idea Right?</td>\n",
       "      <td>Olivia Rodrigo</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Meltdown</td>\n",
       "      <td>Travis Scott Featuring Drake</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Dial Drunk</td>\n",
       "      <td>Noah Kahan With Post Malone</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Tourniquet</td>\n",
       "      <td>Zach Bryan</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Try That In A Small Town</td>\n",
       "      <td>Jason Aldean</td>\n",
       "      <td>21</td>\n",
       "      <td>14</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Qlona</td>\n",
       "      <td>Karol G &amp; Peso Pluma</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>Tulum</td>\n",
       "      <td>Peso Pluma &amp; Grupo Frontera</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Where She Goes</td>\n",
       "      <td>Bad Bunny</td>\n",
       "      <td>51</td>\n",
       "      <td>34</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Angels Don't Always Have Wings</td>\n",
       "      <td>Thomas Rhett</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>K-POP</td>\n",
       "      <td>Travis Scott, Bad Bunny &amp; The Weeknd</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Johnny Dang</td>\n",
       "      <td>That Mexican OT, Paul Wall &amp; DRODi</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Oh U Went</td>\n",
       "      <td>Young Thug Featuring Drake</td>\n",
       "      <td>-</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Dawns</td>\n",
       "      <td>Zach Bryan Featuring Maggie Rogers</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Jake's Piano - Long Island</td>\n",
       "      <td>Zach Bryan</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Save Me</td>\n",
       "      <td>Jelly Roll With Lainey Wilson</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Oklahoma Smoke Show</td>\n",
       "      <td>Zach Bryan</td>\n",
       "      <td>18</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Lose Control</td>\n",
       "      <td>Teddy Swims</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Tradesman</td>\n",
       "      <td>Zach Bryan</td>\n",
       "      <td>53</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Shake Sumn</td>\n",
       "      <td>DaBaby</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Keep Going Up!</td>\n",
       "      <td>Timbaland, Nelly Furtado &amp; Justin Timberlake</td>\n",
       "      <td>52</td>\n",
       "      <td>40</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Area Codes</td>\n",
       "      <td>Kaliii</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Sittin' On Top Of The World</td>\n",
       "      <td>Burna Boy</td>\n",
       "      <td>50</td>\n",
       "      <td>22</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Pretty Little Poison</td>\n",
       "      <td>Warren Zeiders</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Oklahoman Son</td>\n",
       "      <td>Zach Bryan</td>\n",
       "      <td>54</td>\n",
       "      <td>43</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>TQM</td>\n",
       "      <td>Fuerza Regida</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>See You Again</td>\n",
       "      <td>Tyler, The Creator Featuring Kali Uchis</td>\n",
       "      <td>48</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Amargura</td>\n",
       "      <td>Karol G</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Girl In Mine</td>\n",
       "      <td>Parmalee</td>\n",
       "      <td>-</td>\n",
       "      <td>46</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>El Amor de Su Vida</td>\n",
       "      <td>Grupo Frontera &amp; Grupo Firme</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Summer Too Hot</td>\n",
       "      <td>Chris Brown</td>\n",
       "      <td>56</td>\n",
       "      <td>35</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Rubicon</td>\n",
       "      <td>Peso Pluma</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Stand By Me</td>\n",
       "      <td>Lil Durk Featuring Morgan Wallen</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Call Your Friends</td>\n",
       "      <td>Rod Wave</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Your Heart Or Mine</td>\n",
       "      <td>Jon Pardi</td>\n",
       "      <td>31</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Primera Cita</td>\n",
       "      <td>Carin Leon</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>S91</td>\n",
       "      <td>Karol G</td>\n",
       "      <td>55</td>\n",
       "      <td>26</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>99 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Song name  \\\n",
       "0            I Remember Everything   \n",
       "1                         Fast Car   \n",
       "2                     Cruel Summer   \n",
       "3                       Last Night   \n",
       "4                  Dance The Night   \n",
       "5                           Snooze   \n",
       "6                         Fukumean   \n",
       "7                          Vampire   \n",
       "8                        Calm Down   \n",
       "9       Rich Men North Of Richmond   \n",
       "10                    Barbie World   \n",
       "11                         Flowers   \n",
       "12                     All My Life   \n",
       "13                     Religiously   \n",
       "14                Used To Be Young   \n",
       "15                      Hey Driver   \n",
       "16                    Need A Favor   \n",
       "17                Thinkin' Bout Me   \n",
       "18                       Anti-Hero   \n",
       "19                       Kill Bill   \n",
       "20            What Was I Made For?   \n",
       "21             Last Time I Saw You   \n",
       "22                           Karma   \n",
       "23                        Creepin'   \n",
       "24                 Bad Idea Right?   \n",
       "25                        Meltdown   \n",
       "26                      Dial Drunk   \n",
       "27                      Tourniquet   \n",
       "28        Try That In A Small Town   \n",
       "29                           Qlona   \n",
       "..                             ...   \n",
       "69                           Tulum   \n",
       "70                  Where She Goes   \n",
       "71  Angels Don't Always Have Wings   \n",
       "72                           K-POP   \n",
       "73                     Johnny Dang   \n",
       "74                       Oh U Went   \n",
       "75                           Dawns   \n",
       "76      Jake's Piano - Long Island   \n",
       "77                         Save Me   \n",
       "78             Oklahoma Smoke Show   \n",
       "79                    Lose Control   \n",
       "80                       Tradesman   \n",
       "81                      Shake Sumn   \n",
       "82                  Keep Going Up!   \n",
       "83                      Area Codes   \n",
       "84     Sittin' On Top Of The World   \n",
       "85            Pretty Little Poison   \n",
       "86                   Oklahoman Son   \n",
       "87                             TQM   \n",
       "88                   See You Again   \n",
       "89                        Amargura   \n",
       "90                    Girl In Mine   \n",
       "91              El Amor de Su Vida   \n",
       "92                  Summer Too Hot   \n",
       "93                         Rubicon   \n",
       "94                     Stand By Me   \n",
       "95               Call Your Friends   \n",
       "96              Your Heart Or Mine   \n",
       "97                    Primera Cita   \n",
       "98                             S91   \n",
       "\n",
       "                                     Artist Name Last Week Rank Peak Rank  \\\n",
       "0           Zach Bryan Featuring Kacey Musgraves              3         1   \n",
       "1                                     Luke Combs                            \n",
       "2                                   Taylor Swift              1         1   \n",
       "3                                  Morgan Wallen                            \n",
       "4                                       Dua Lipa              2         2   \n",
       "5                                            SZA                            \n",
       "6                                          Gunna              5         3   \n",
       "7                                 Olivia Rodrigo                            \n",
       "8                            Rema & Selena Gomez              4         1   \n",
       "9                           Oliver Anthony Music                            \n",
       "10             Nicki Minaj & Ice Spice With Aqua              9         6   \n",
       "11                                   Miley Cyrus                            \n",
       "12                    Lil Durk Featuring J. Cole              7         7   \n",
       "13                              Bailey Zimmerman                            \n",
       "14                                   Miley Cyrus             10         4   \n",
       "15       Zach Bryan Featuring The War And Treaty                            \n",
       "16                                    Jelly Roll             12         1   \n",
       "17                                 Morgan Wallen                            \n",
       "18                                  Taylor Swift             11         3   \n",
       "19                                           SZA                            \n",
       "20                                 Billie Eilish              6         1   \n",
       "21                                   Nicki Minaj                            \n",
       "22              Taylor Swift Featuring Ice Spice             13         7   \n",
       "23          Metro Boomin, The Weeknd & 21 Savage                            \n",
       "24                                Olivia Rodrigo             15         1   \n",
       "25                  Travis Scott Featuring Drake                            \n",
       "26                   Noah Kahan With Post Malone             16         2   \n",
       "27                                    Zach Bryan                            \n",
       "28                                  Jason Aldean             21        14   \n",
       "29                          Karol G & Peso Pluma                            \n",
       "..                                           ...            ...       ...   \n",
       "69                   Peso Pluma & Grupo Frontera                            \n",
       "70                                     Bad Bunny             51        34   \n",
       "71                                  Thomas Rhett                            \n",
       "72          Travis Scott, Bad Bunny & The Weeknd             28         1   \n",
       "73            That Mexican OT, Paul Wall & DRODi                            \n",
       "74                    Young Thug Featuring Drake              -         8   \n",
       "75            Zach Bryan Featuring Maggie Rogers                            \n",
       "76                                    Zach Bryan             19        19   \n",
       "77                 Jelly Roll With Lainey Wilson                            \n",
       "78                                    Zach Bryan             18        18   \n",
       "79                                   Teddy Swims                            \n",
       "80                                    Zach Bryan             53        41   \n",
       "81                                        DaBaby                            \n",
       "82  Timbaland, Nelly Furtado & Justin Timberlake             52        40   \n",
       "83                                        Kaliii                            \n",
       "84                                     Burna Boy             50        22   \n",
       "85                                Warren Zeiders                            \n",
       "86                                    Zach Bryan             54        43   \n",
       "87                                 Fuerza Regida                            \n",
       "88       Tyler, The Creator Featuring Kali Uchis             48        17   \n",
       "89                                       Karol G                            \n",
       "90                                      Parmalee              -        46   \n",
       "91                  Grupo Frontera & Grupo Firme                            \n",
       "92                                   Chris Brown             56        35   \n",
       "93                                    Peso Pluma                            \n",
       "94              Lil Durk Featuring Morgan Wallen             24        24   \n",
       "95                                      Rod Wave                            \n",
       "96                                     Jon Pardi             31        31   \n",
       "97                                    Carin Leon                            \n",
       "98                                       Karol G             55        26   \n",
       "\n",
       "   Weeks on board  \n",
       "0               5  \n",
       "1               2  \n",
       "2              24  \n",
       "3              18  \n",
       "4              32  \n",
       "5              15  \n",
       "6              39  \n",
       "7              12  \n",
       "8              10  \n",
       "9              53  \n",
       "10              4  \n",
       "11             11  \n",
       "12             34  \n",
       "13             17  \n",
       "14             18  \n",
       "15              2  \n",
       "16              2  \n",
       "17             23  \n",
       "18             27  \n",
       "19             46  \n",
       "20             39  \n",
       "21              8  \n",
       "22              1  \n",
       "23             26  \n",
       "24             40  \n",
       "25              4  \n",
       "26              6  \n",
       "27             12  \n",
       "28              2  \n",
       "29              8  \n",
       "..            ...  \n",
       "69             11  \n",
       "70             10  \n",
       "71             16  \n",
       "72              7  \n",
       "73              7  \n",
       "74              8  \n",
       "75             11  \n",
       "76             19  \n",
       "77              2  \n",
       "78             12  \n",
       "79              7  \n",
       "80              4  \n",
       "81              2  \n",
       "82             16  \n",
       "83              1  \n",
       "84             18  \n",
       "85              2  \n",
       "86              4  \n",
       "87              2  \n",
       "88             16  \n",
       "89             20  \n",
       "90              4  \n",
       "91              6  \n",
       "92              3  \n",
       "93              3  \n",
       "94             10  \n",
       "95             15  \n",
       "96              3  \n",
       "97             17  \n",
       "98              2  \n",
       "\n",
       "[99 rows x 5 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.DataFrame()\n",
    "df['Song name']=Song[:100]\n",
    "df['Artist Name']=Artist[:100]\n",
    "df['Last Week Rank']=Last_Week_Rank[:100]\n",
    "df['Peak Rank']=Peak_Rank[:100]\n",
    "df['Weeks on board']=Board[:100]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 6 Scrape the details of Highest selling novels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Da Vinci Code,The',\n",
       " 'Harry Potter and the Deathly Hallows',\n",
       " \"Harry Potter and the Philosopher's Stone\",\n",
       " 'Harry Potter and the Order of the Phoenix',\n",
       " 'Fifty Shades of Grey',\n",
       " 'Harry Potter and the Goblet of Fire',\n",
       " 'Harry Potter and the Chamber of Secrets',\n",
       " 'Harry Potter and the Prisoner of Azkaban',\n",
       " 'Angels and Demons',\n",
       " \"Harry Potter and the Half-blood Prince:Children's Edition\",\n",
       " 'Fifty Shades Darker',\n",
       " 'Twilight',\n",
       " 'Girl with the Dragon Tattoo,The:Millennium Trilogy',\n",
       " 'Fifty Shades Freed',\n",
       " 'Lost Symbol,The',\n",
       " 'New Moon',\n",
       " 'Deception Point',\n",
       " 'Eclipse',\n",
       " 'Lovely Bones,The',\n",
       " 'Curious Incident of the Dog in the Night-time,The',\n",
       " 'Digital Fortress',\n",
       " 'Short History of Nearly Everything,A',\n",
       " 'Girl Who Played with Fire,The:Millennium Trilogy',\n",
       " 'Breaking Dawn',\n",
       " 'Very Hungry Caterpillar,The:The Very Hungry Caterpillar',\n",
       " 'Gruffalo,The',\n",
       " \"Jamie's 30-Minute Meals\",\n",
       " 'Kite Runner,The',\n",
       " 'One Day',\n",
       " 'Thousand Splendid Suns,A',\n",
       " \"Girl Who Kicked the Hornets' Nest,The:Millennium Trilogy\",\n",
       " \"Time Traveler's Wife,The\",\n",
       " 'Atonement',\n",
       " \"Bridget Jones's Diary:A Novel\",\n",
       " 'World According to Clarkson,The',\n",
       " \"Captain Corelli's Mandolin\",\n",
       " 'Sound of Laughter,The',\n",
       " 'Life of Pi',\n",
       " 'Billy Connolly',\n",
       " 'Child Called It,A',\n",
       " \"Gruffalo's Child,The\",\n",
       " \"Angela's Ashes:A Memoir of a Childhood\",\n",
       " 'Birdsong',\n",
       " 'Northern Lights:His Dark Materials S.',\n",
       " 'Labyrinth',\n",
       " 'Harry Potter and the Half-blood Prince',\n",
       " 'Help,The',\n",
       " 'Man and Boy',\n",
       " 'Memoirs of a Geisha',\n",
       " \"No.1 Ladies' Detective Agency,The:No.1 Ladies' Detective Agency S.\",\n",
       " 'Island,The',\n",
       " 'PS, I Love You',\n",
       " 'You are What You Eat:The Plan That Will Change Your Life',\n",
       " 'Shadow of the Wind,The',\n",
       " 'Tales of Beedle the Bard,The',\n",
       " 'Broker,The',\n",
       " \"Dr. Atkins' New Diet Revolution:The No-hunger, Luxurious Weight Loss P\",\n",
       " 'Subtle Knife,The:His Dark Materials S.',\n",
       " 'Eats, Shoots and Leaves:The Zero Tolerance Approach to Punctuation',\n",
       " \"Delia's How to Cook:(Bk.1)\",\n",
       " 'Chocolat',\n",
       " 'Boy in the Striped Pyjamas,The',\n",
       " \"My Sister's Keeper\",\n",
       " 'Amber Spyglass,The:His Dark Materials S.',\n",
       " 'To Kill a Mockingbird',\n",
       " 'Men are from Mars, Women are from Venus:A Practical Guide for Improvin',\n",
       " 'Dear Fatty',\n",
       " 'Short History of Tractors in Ukrainian,A',\n",
       " 'Hannibal',\n",
       " 'Lord of the Rings,The',\n",
       " 'Stupid White Men:...and Other Sorry Excuses for the State of the Natio',\n",
       " 'Interpretation of Murder,The',\n",
       " 'Sharon Osbourne Extreme:My Autobiography',\n",
       " 'Alchemist,The:A Fable About Following Your Dream',\n",
       " \"At My Mother's Knee ...:and Other Low Joints\",\n",
       " 'Notes from a Small Island',\n",
       " 'Return of the Naked Chef,The',\n",
       " 'Bridget Jones: The Edge of Reason',\n",
       " \"Jamie's Italy\",\n",
       " 'I Can Make You Thin',\n",
       " 'Down Under',\n",
       " 'Summons,The',\n",
       " 'Small Island',\n",
       " 'Nigella Express',\n",
       " 'Brick Lane',\n",
       " \"Memory Keeper's Daughter,The\",\n",
       " 'Room on the Broom',\n",
       " 'About a Boy',\n",
       " 'My Booky Wook',\n",
       " 'God Delusion,The',\n",
       " '\"Beano\" Annual,The',\n",
       " 'White Teeth',\n",
       " 'House at Riverton,The',\n",
       " 'Book Thief,The',\n",
       " 'Nights of Rain and Stars',\n",
       " 'Ghost,The',\n",
       " 'Happy Days with the Naked Chef',\n",
       " 'Hunger Games,The:Hunger Games Trilogy',\n",
       " \"Lost Boy,The:A Foster Child's Search for the Love of a Family\",\n",
       " \"Jamie's Ministry of Food:Anyone Can Learn to Cook in 24 Hours\"]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrpae all Book Name\n",
    "\n",
    "b = driver.find_elements(By.XPATH,\"//td[2]\")\n",
    "\n",
    "Book=[]\n",
    "\n",
    "for i in b:\n",
    "    Book.append(i.text)\n",
    "    \n",
    "Book    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Brown, Dan',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'James, E. L.',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'Rowling, J.K.',\n",
       " 'Brown, Dan',\n",
       " 'Rowling, J.K.',\n",
       " 'James, E. L.',\n",
       " 'Meyer, Stephenie',\n",
       " 'Larsson, Stieg',\n",
       " 'James, E. L.',\n",
       " 'Brown, Dan',\n",
       " 'Meyer, Stephenie',\n",
       " 'Brown, Dan',\n",
       " 'Meyer, Stephenie',\n",
       " 'Sebold, Alice',\n",
       " 'Haddon, Mark',\n",
       " 'Brown, Dan',\n",
       " 'Bryson, Bill',\n",
       " 'Larsson, Stieg',\n",
       " 'Meyer, Stephenie',\n",
       " 'Carle, Eric',\n",
       " 'Donaldson, Julia',\n",
       " 'Oliver, Jamie',\n",
       " 'Hosseini, Khaled',\n",
       " 'Nicholls, David',\n",
       " 'Hosseini, Khaled',\n",
       " 'Larsson, Stieg',\n",
       " 'Niffenegger, Audrey',\n",
       " 'McEwan, Ian',\n",
       " 'Fielding, Helen',\n",
       " 'Clarkson, Jeremy',\n",
       " 'Bernieres, Louis de',\n",
       " 'Kay, Peter',\n",
       " 'Martel, Yann',\n",
       " 'Stephenson, Pamela',\n",
       " 'Pelzer, Dave',\n",
       " 'Donaldson, Julia',\n",
       " 'McCourt, Frank',\n",
       " 'Faulks, Sebastian',\n",
       " 'Pullman, Philip',\n",
       " 'Mosse, Kate',\n",
       " 'Rowling, J.K.',\n",
       " 'Stockett, Kathryn',\n",
       " 'Parsons, Tony',\n",
       " 'Golden, Arthur',\n",
       " 'McCall Smith, Alexander',\n",
       " 'Hislop, Victoria',\n",
       " 'Ahern, Cecelia',\n",
       " 'McKeith, Gillian',\n",
       " 'Zafon, Carlos Ruiz',\n",
       " 'Rowling, J.K.',\n",
       " 'Grisham, John',\n",
       " 'Atkins, Robert C.',\n",
       " 'Pullman, Philip',\n",
       " 'Truss, Lynne',\n",
       " 'Smith, Delia',\n",
       " 'Harris, Joanne',\n",
       " 'Boyne, John',\n",
       " 'Picoult, Jodi',\n",
       " 'Pullman, Philip',\n",
       " 'Lee, Harper',\n",
       " 'Gray, John',\n",
       " 'French, Dawn',\n",
       " 'Lewycka, Marina',\n",
       " 'Harris, Thomas',\n",
       " 'Tolkien, J. R. R.',\n",
       " 'Moore, Michael',\n",
       " 'Rubenfeld, Jed',\n",
       " 'Osbourne, Sharon',\n",
       " 'Coelho, Paulo',\n",
       " \"O'Grady, Paul\",\n",
       " 'Bryson, Bill',\n",
       " 'Oliver, Jamie',\n",
       " 'Fielding, Helen',\n",
       " 'Oliver, Jamie',\n",
       " 'McKenna, Paul',\n",
       " 'Bryson, Bill',\n",
       " 'Grisham, John',\n",
       " 'Levy, Andrea',\n",
       " 'Lawson, Nigella',\n",
       " 'Ali, Monica',\n",
       " 'Edwards, Kim',\n",
       " 'Donaldson, Julia',\n",
       " 'Hornby, Nick',\n",
       " 'Brand, Russell',\n",
       " 'Dawkins, Richard',\n",
       " '0',\n",
       " 'Smith, Zadie',\n",
       " 'Morton, Kate',\n",
       " 'Zusak, Markus',\n",
       " 'Binchy, Maeve',\n",
       " 'Harris, Robert',\n",
       " 'Oliver, Jamie',\n",
       " 'Collins, Suzanne',\n",
       " 'Pelzer, Dave',\n",
       " 'Oliver, Jamie']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrpae all Author Name\n",
    "\n",
    "a = driver.find_elements(By.XPATH,\"//td[3]\")\n",
    "\n",
    "Author=[]\n",
    "\n",
    "for i in a:\n",
    "    Author.append(i.text)\n",
    "    \n",
    "Author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5,094,805',\n",
       " '4,475,152',\n",
       " '4,200,654',\n",
       " '4,179,479',\n",
       " '3,758,936',\n",
       " '3,583,215',\n",
       " '3,484,047',\n",
       " '3,377,906',\n",
       " '3,193,946',\n",
       " '2,950,264',\n",
       " '2,479,784',\n",
       " '2,315,405',\n",
       " '2,233,570',\n",
       " '2,193,928',\n",
       " '2,183,031',\n",
       " '2,152,737',\n",
       " '2,062,145',\n",
       " '2,052,876',\n",
       " '2,005,598',\n",
       " '1,979,552',\n",
       " '1,928,900',\n",
       " '1,852,919',\n",
       " '1,814,784',\n",
       " '1,787,118',\n",
       " '1,783,535',\n",
       " '1,781,269',\n",
       " '1,743,266',\n",
       " '1,629,119',\n",
       " '1,616,068',\n",
       " '1,583,992',\n",
       " '1,555,135',\n",
       " '1,546,886',\n",
       " '1,539,428',\n",
       " '1,508,205',\n",
       " '1,489,403',\n",
       " '1,352,318',\n",
       " '1,310,207',\n",
       " '1,310,176',\n",
       " '1,231,957',\n",
       " '1,217,712',\n",
       " '1,208,711',\n",
       " '1,204,058',\n",
       " '1,184,967',\n",
       " '1,181,503',\n",
       " '1,181,093',\n",
       " '1,153,181',\n",
       " '1,132,336',\n",
       " '1,130,802',\n",
       " '1,126,337',\n",
       " '1,115,549',\n",
       " '1,108,328',\n",
       " '1,107,379',\n",
       " '1,104,403',\n",
       " '1,092,349',\n",
       " '1,090,847',\n",
       " '1,087,262',\n",
       " '1,054,196',\n",
       " '1,037,160',\n",
       " '1,023,688',\n",
       " '1,015,956',\n",
       " '1,009,873',\n",
       " '1,004,414',\n",
       " '1,003,780',\n",
       " '1,002,314',\n",
       " '998,213',\n",
       " '992,846',\n",
       " '986,753',\n",
       " '986,115',\n",
       " '970,509',\n",
       " '967,466',\n",
       " '963,353',\n",
       " '962,515',\n",
       " '959,496',\n",
       " '956,114',\n",
       " '945,640',\n",
       " '931,312',\n",
       " '925,425',\n",
       " '924,695',\n",
       " '906,968',\n",
       " '905,086',\n",
       " '890,847',\n",
       " '869,671',\n",
       " '869,659',\n",
       " '862,602',\n",
       " '856,540',\n",
       " '845,858',\n",
       " '842,535',\n",
       " '828,215',\n",
       " '820,563',\n",
       " '816,907',\n",
       " '816,585',\n",
       " '815,586',\n",
       " '814,370',\n",
       " '809,641',\n",
       " '808,900',\n",
       " '807,311',\n",
       " '794,201',\n",
       " '792,187',\n",
       " '791,507',\n",
       " '791,095']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrpae all Volumes Sold\n",
    "\n",
    "v = driver.find_elements(By.XPATH,\"//td[4]\")\n",
    "\n",
    "Sold=[]\n",
    "\n",
    "for i in v:\n",
    "    Sold.append(i.text)\n",
    "    \n",
    "Sold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Transworld',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Random House',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Bloomsbury',\n",
       " 'Transworld',\n",
       " 'Bloomsbury',\n",
       " 'Random House',\n",
       " 'Little, Brown Book',\n",
       " 'Quercus',\n",
       " 'Random House',\n",
       " 'Transworld',\n",
       " 'Little, Brown Book',\n",
       " 'Transworld',\n",
       " 'Little, Brown Book',\n",
       " 'Pan Macmillan',\n",
       " 'Random House',\n",
       " 'Transworld',\n",
       " 'Transworld',\n",
       " 'Quercus',\n",
       " 'Little, Brown Book',\n",
       " 'Penguin',\n",
       " 'Pan Macmillan',\n",
       " 'Penguin',\n",
       " 'Bloomsbury',\n",
       " 'Hodder & Stoughton',\n",
       " 'Bloomsbury',\n",
       " 'Quercus',\n",
       " 'Random House',\n",
       " 'Random House',\n",
       " 'Pan Macmillan',\n",
       " 'Penguin',\n",
       " 'Random House',\n",
       " 'Random House',\n",
       " 'Canongate',\n",
       " 'HarperCollins',\n",
       " 'Orion',\n",
       " 'Pan Macmillan',\n",
       " 'HarperCollins',\n",
       " 'Random House',\n",
       " 'Scholastic Ltd.',\n",
       " 'Orion',\n",
       " 'Bloomsbury',\n",
       " 'Penguin',\n",
       " 'HarperCollins',\n",
       " 'Random House',\n",
       " 'Little, Brown Book',\n",
       " 'Headline',\n",
       " 'HarperCollins',\n",
       " 'Penguin',\n",
       " 'Orion',\n",
       " 'Bloomsbury',\n",
       " 'Random House',\n",
       " 'Random House',\n",
       " 'Scholastic Ltd.',\n",
       " 'Profile Books Group',\n",
       " 'Random House',\n",
       " 'Transworld',\n",
       " 'Random House Childrens Books G',\n",
       " 'Hodder & Stoughton',\n",
       " 'Scholastic Ltd.',\n",
       " 'Random House',\n",
       " 'HarperCollins',\n",
       " 'Random House',\n",
       " 'Penguin',\n",
       " 'Random House',\n",
       " 'HarperCollins',\n",
       " 'Penguin',\n",
       " 'Headline',\n",
       " 'Little, Brown Book',\n",
       " 'HarperCollins',\n",
       " 'Transworld',\n",
       " 'Transworld',\n",
       " 'Penguin',\n",
       " 'Pan Macmillan',\n",
       " 'Penguin',\n",
       " 'Transworld',\n",
       " 'Transworld',\n",
       " 'Random House',\n",
       " 'Headline',\n",
       " 'Random House',\n",
       " 'Transworld',\n",
       " 'Penguin',\n",
       " 'Pan Macmillan',\n",
       " 'Penguin',\n",
       " 'Hodder & Stoughton',\n",
       " 'Transworld',\n",
       " 'D.C. Thomson',\n",
       " 'Penguin',\n",
       " 'Pan Macmillan',\n",
       " 'Transworld',\n",
       " 'Orion',\n",
       " 'Random House',\n",
       " 'Penguin',\n",
       " 'Scholastic Ltd.',\n",
       " 'Orion',\n",
       " 'Penguin']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrpae all Publisher\n",
    "\n",
    "p = driver.find_elements(By.XPATH,\"//td[5]\")\n",
    "\n",
    "Publisher=[]\n",
    "\n",
    "for i in p:\n",
    "    Publisher.append(i.text)\n",
    "    \n",
    "Publisher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Crime, Thriller & Adventure',\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " 'Romance & Sagas',\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " \"Children's Fiction\",\n",
       " 'Crime, Thriller & Adventure',\n",
       " \"Children's Fiction\",\n",
       " 'Romance & Sagas',\n",
       " 'Young Adult Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Romance & Sagas',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Young Adult Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Popular Science',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Young Adult Fiction',\n",
       " 'Picture Books',\n",
       " 'Picture Books',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Humour: Collections & General',\n",
       " 'General & Literary Fiction',\n",
       " 'Autobiography: General',\n",
       " 'General & Literary Fiction',\n",
       " 'Biography: The Arts',\n",
       " 'Autobiography: General',\n",
       " 'Picture Books',\n",
       " 'Autobiography: General',\n",
       " 'General & Literary Fiction',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Science Fiction & Fantasy',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Fitness & Diet',\n",
       " 'General & Literary Fiction',\n",
       " \"Children's Fiction\",\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Fitness & Diet',\n",
       " 'Young Adult Fiction',\n",
       " 'Usage & Writing Guides',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Young Adult Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Popular Culture & Media: General Interest',\n",
       " 'Autobiography: The Arts',\n",
       " 'General & Literary Fiction',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Science Fiction & Fantasy',\n",
       " 'Current Affairs & Issues',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'Autobiography: The Arts',\n",
       " 'General & Literary Fiction',\n",
       " 'Autobiography: The Arts',\n",
       " 'Travel Writing',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'National & Regional Cuisine',\n",
       " 'Fitness & Diet',\n",
       " 'Travel Writing',\n",
       " 'Crime, Thriller & Adventure',\n",
       " 'General & Literary Fiction',\n",
       " 'Food & Drink: General',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Picture Books',\n",
       " 'General & Literary Fiction',\n",
       " 'Autobiography: The Arts',\n",
       " 'Popular Science',\n",
       " \"Children's Annuals\",\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'General & Literary Fiction',\n",
       " 'Food & Drink: General',\n",
       " 'Young Adult Fiction',\n",
       " 'Biography: General',\n",
       " 'Food & Drink: General']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrpae all Genre\n",
    "\n",
    "g = driver.find_elements(By.XPATH,\"//td[6]\")\n",
    "\n",
    "Genre=[]\n",
    "\n",
    "for i in g:\n",
    "    Genre.append(i.text)\n",
    "    \n",
    "Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Book),len(Author),len(Sold),len(Publisher),len(Genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volumes Sold</th>\n",
       "      <th>Publisher Name</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Harry Potter and the Goblet of Fire</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>3,583,215</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Harry Potter and the Chamber of Secrets</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>3,484,047</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Harry Potter and the Prisoner of Azkaban</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>3,377,906</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Angels and Demons</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>3,193,946</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Harry Potter and the Half-blood Prince:Childre...</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>2,950,264</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Fifty Shades Darker</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>2,479,784</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Twilight</td>\n",
       "      <td>Meyer, Stephenie</td>\n",
       "      <td>2,315,405</td>\n",
       "      <td>Little, Brown Book</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Girl with the Dragon Tattoo,The:Millennium Tri...</td>\n",
       "      <td>Larsson, Stieg</td>\n",
       "      <td>2,233,570</td>\n",
       "      <td>Quercus</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Fifty Shades Freed</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>2,193,928</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Lost Symbol,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>2,183,031</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>New Moon</td>\n",
       "      <td>Meyer, Stephenie</td>\n",
       "      <td>2,152,737</td>\n",
       "      <td>Little, Brown Book</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Deception Point</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>2,062,145</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Eclipse</td>\n",
       "      <td>Meyer, Stephenie</td>\n",
       "      <td>2,052,876</td>\n",
       "      <td>Little, Brown Book</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Lovely Bones,The</td>\n",
       "      <td>Sebold, Alice</td>\n",
       "      <td>2,005,598</td>\n",
       "      <td>Pan Macmillan</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Curious Incident of the Dog in the Night-time,The</td>\n",
       "      <td>Haddon, Mark</td>\n",
       "      <td>1,979,552</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Digital Fortress</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>1,928,900</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Short History of Nearly Everything,A</td>\n",
       "      <td>Bryson, Bill</td>\n",
       "      <td>1,852,919</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Popular Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Girl Who Played with Fire,The:Millennium Trilogy</td>\n",
       "      <td>Larsson, Stieg</td>\n",
       "      <td>1,814,784</td>\n",
       "      <td>Quercus</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Breaking Dawn</td>\n",
       "      <td>Meyer, Stephenie</td>\n",
       "      <td>1,787,118</td>\n",
       "      <td>Little, Brown Book</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Very Hungry Caterpillar,The:The Very Hungry Ca...</td>\n",
       "      <td>Carle, Eric</td>\n",
       "      <td>1,783,535</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Picture Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Gruffalo,The</td>\n",
       "      <td>Donaldson, Julia</td>\n",
       "      <td>1,781,269</td>\n",
       "      <td>Pan Macmillan</td>\n",
       "      <td>Picture Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Jamie's 30-Minute Meals</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>1,743,266</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Kite Runner,The</td>\n",
       "      <td>Hosseini, Khaled</td>\n",
       "      <td>1,629,119</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>One Day</td>\n",
       "      <td>Nicholls, David</td>\n",
       "      <td>1,616,068</td>\n",
       "      <td>Hodder &amp; Stoughton</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Thousand Splendid Suns,A</td>\n",
       "      <td>Hosseini, Khaled</td>\n",
       "      <td>1,583,992</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Stupid White Men:...and Other Sorry Excuses fo...</td>\n",
       "      <td>Moore, Michael</td>\n",
       "      <td>963,353</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Current Affairs &amp; Issues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>Interpretation of Murder,The</td>\n",
       "      <td>Rubenfeld, Jed</td>\n",
       "      <td>962,515</td>\n",
       "      <td>Headline</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Sharon Osbourne Extreme:My Autobiography</td>\n",
       "      <td>Osbourne, Sharon</td>\n",
       "      <td>959,496</td>\n",
       "      <td>Little, Brown Book</td>\n",
       "      <td>Autobiography: The Arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Alchemist,The:A Fable About Following Your Dream</td>\n",
       "      <td>Coelho, Paulo</td>\n",
       "      <td>956,114</td>\n",
       "      <td>HarperCollins</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>At My Mother's Knee ...:and Other Low Joints</td>\n",
       "      <td>O'Grady, Paul</td>\n",
       "      <td>945,640</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Autobiography: The Arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Notes from a Small Island</td>\n",
       "      <td>Bryson, Bill</td>\n",
       "      <td>931,312</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Travel Writing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Return of the Naked Chef,The</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>925,425</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Bridget Jones: The Edge of Reason</td>\n",
       "      <td>Fielding, Helen</td>\n",
       "      <td>924,695</td>\n",
       "      <td>Pan Macmillan</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Jamie's Italy</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>906,968</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>National &amp; Regional Cuisine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>I Can Make You Thin</td>\n",
       "      <td>McKenna, Paul</td>\n",
       "      <td>905,086</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Fitness &amp; Diet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Down Under</td>\n",
       "      <td>Bryson, Bill</td>\n",
       "      <td>890,847</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Travel Writing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Summons,The</td>\n",
       "      <td>Grisham, John</td>\n",
       "      <td>869,671</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Small Island</td>\n",
       "      <td>Levy, Andrea</td>\n",
       "      <td>869,659</td>\n",
       "      <td>Headline</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>Nigella Express</td>\n",
       "      <td>Lawson, Nigella</td>\n",
       "      <td>862,602</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Brick Lane</td>\n",
       "      <td>Ali, Monica</td>\n",
       "      <td>856,540</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Memory Keeper's Daughter,The</td>\n",
       "      <td>Edwards, Kim</td>\n",
       "      <td>845,858</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Room on the Broom</td>\n",
       "      <td>Donaldson, Julia</td>\n",
       "      <td>842,535</td>\n",
       "      <td>Pan Macmillan</td>\n",
       "      <td>Picture Books</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>About a Boy</td>\n",
       "      <td>Hornby, Nick</td>\n",
       "      <td>828,215</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>My Booky Wook</td>\n",
       "      <td>Brand, Russell</td>\n",
       "      <td>820,563</td>\n",
       "      <td>Hodder &amp; Stoughton</td>\n",
       "      <td>Autobiography: The Arts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>God Delusion,The</td>\n",
       "      <td>Dawkins, Richard</td>\n",
       "      <td>816,907</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Popular Science</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>\"Beano\" Annual,The</td>\n",
       "      <td>0</td>\n",
       "      <td>816,585</td>\n",
       "      <td>D.C. Thomson</td>\n",
       "      <td>Children's Annuals</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>White Teeth</td>\n",
       "      <td>Smith, Zadie</td>\n",
       "      <td>815,586</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>House at Riverton,The</td>\n",
       "      <td>Morton, Kate</td>\n",
       "      <td>814,370</td>\n",
       "      <td>Pan Macmillan</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Book Thief,The</td>\n",
       "      <td>Zusak, Markus</td>\n",
       "      <td>809,641</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>Nights of Rain and Stars</td>\n",
       "      <td>Binchy, Maeve</td>\n",
       "      <td>808,900</td>\n",
       "      <td>Orion</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name       Author Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "5                 Harry Potter and the Goblet of Fire     Rowling, J.K.   \n",
       "6             Harry Potter and the Chamber of Secrets     Rowling, J.K.   \n",
       "7            Harry Potter and the Prisoner of Azkaban     Rowling, J.K.   \n",
       "8                                   Angels and Demons        Brown, Dan   \n",
       "9   Harry Potter and the Half-blood Prince:Childre...     Rowling, J.K.   \n",
       "10                                Fifty Shades Darker      James, E. L.   \n",
       "11                                           Twilight  Meyer, Stephenie   \n",
       "12  Girl with the Dragon Tattoo,The:Millennium Tri...    Larsson, Stieg   \n",
       "13                                 Fifty Shades Freed      James, E. L.   \n",
       "14                                    Lost Symbol,The        Brown, Dan   \n",
       "15                                           New Moon  Meyer, Stephenie   \n",
       "16                                    Deception Point        Brown, Dan   \n",
       "17                                            Eclipse  Meyer, Stephenie   \n",
       "18                                   Lovely Bones,The     Sebold, Alice   \n",
       "19  Curious Incident of the Dog in the Night-time,The      Haddon, Mark   \n",
       "20                                   Digital Fortress        Brown, Dan   \n",
       "21               Short History of Nearly Everything,A      Bryson, Bill   \n",
       "22   Girl Who Played with Fire,The:Millennium Trilogy    Larsson, Stieg   \n",
       "23                                      Breaking Dawn  Meyer, Stephenie   \n",
       "24  Very Hungry Caterpillar,The:The Very Hungry Ca...       Carle, Eric   \n",
       "25                                       Gruffalo,The  Donaldson, Julia   \n",
       "26                            Jamie's 30-Minute Meals     Oliver, Jamie   \n",
       "27                                    Kite Runner,The  Hosseini, Khaled   \n",
       "28                                            One Day   Nicholls, David   \n",
       "29                           Thousand Splendid Suns,A  Hosseini, Khaled   \n",
       "..                                                ...               ...   \n",
       "70  Stupid White Men:...and Other Sorry Excuses fo...    Moore, Michael   \n",
       "71                       Interpretation of Murder,The    Rubenfeld, Jed   \n",
       "72           Sharon Osbourne Extreme:My Autobiography  Osbourne, Sharon   \n",
       "73   Alchemist,The:A Fable About Following Your Dream     Coelho, Paulo   \n",
       "74       At My Mother's Knee ...:and Other Low Joints     O'Grady, Paul   \n",
       "75                          Notes from a Small Island      Bryson, Bill   \n",
       "76                       Return of the Naked Chef,The     Oliver, Jamie   \n",
       "77                  Bridget Jones: The Edge of Reason   Fielding, Helen   \n",
       "78                                      Jamie's Italy     Oliver, Jamie   \n",
       "79                                I Can Make You Thin     McKenna, Paul   \n",
       "80                                         Down Under      Bryson, Bill   \n",
       "81                                        Summons,The     Grisham, John   \n",
       "82                                       Small Island      Levy, Andrea   \n",
       "83                                    Nigella Express   Lawson, Nigella   \n",
       "84                                         Brick Lane       Ali, Monica   \n",
       "85                       Memory Keeper's Daughter,The      Edwards, Kim   \n",
       "86                                  Room on the Broom  Donaldson, Julia   \n",
       "87                                        About a Boy      Hornby, Nick   \n",
       "88                                      My Booky Wook    Brand, Russell   \n",
       "89                                   God Delusion,The  Dawkins, Richard   \n",
       "90                                 \"Beano\" Annual,The                 0   \n",
       "91                                        White Teeth      Smith, Zadie   \n",
       "92                              House at Riverton,The      Morton, Kate   \n",
       "93                                     Book Thief,The     Zusak, Markus   \n",
       "94                           Nights of Rain and Stars     Binchy, Maeve   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes Sold      Publisher Name                        Genre  \n",
       "0     5,094,805          Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152          Bloomsbury           Children's Fiction  \n",
       "2     4,200,654          Bloomsbury           Children's Fiction  \n",
       "3     4,179,479          Bloomsbury           Children's Fiction  \n",
       "4     3,758,936        Random House              Romance & Sagas  \n",
       "5     3,583,215          Bloomsbury           Children's Fiction  \n",
       "6     3,484,047          Bloomsbury           Children's Fiction  \n",
       "7     3,377,906          Bloomsbury           Children's Fiction  \n",
       "8     3,193,946          Transworld  Crime, Thriller & Adventure  \n",
       "9     2,950,264          Bloomsbury           Children's Fiction  \n",
       "10    2,479,784        Random House              Romance & Sagas  \n",
       "11    2,315,405  Little, Brown Book          Young Adult Fiction  \n",
       "12    2,233,570             Quercus  Crime, Thriller & Adventure  \n",
       "13    2,193,928        Random House              Romance & Sagas  \n",
       "14    2,183,031          Transworld  Crime, Thriller & Adventure  \n",
       "15    2,152,737  Little, Brown Book          Young Adult Fiction  \n",
       "16    2,062,145          Transworld  Crime, Thriller & Adventure  \n",
       "17    2,052,876  Little, Brown Book          Young Adult Fiction  \n",
       "18    2,005,598       Pan Macmillan   General & Literary Fiction  \n",
       "19    1,979,552        Random House   General & Literary Fiction  \n",
       "20    1,928,900          Transworld  Crime, Thriller & Adventure  \n",
       "21    1,852,919          Transworld              Popular Science  \n",
       "22    1,814,784             Quercus  Crime, Thriller & Adventure  \n",
       "23    1,787,118  Little, Brown Book          Young Adult Fiction  \n",
       "24    1,783,535             Penguin                Picture Books  \n",
       "25    1,781,269       Pan Macmillan                Picture Books  \n",
       "26    1,743,266             Penguin        Food & Drink: General  \n",
       "27    1,629,119          Bloomsbury   General & Literary Fiction  \n",
       "28    1,616,068  Hodder & Stoughton   General & Literary Fiction  \n",
       "29    1,583,992          Bloomsbury   General & Literary Fiction  \n",
       "..          ...                 ...                          ...  \n",
       "70      963,353             Penguin     Current Affairs & Issues  \n",
       "71      962,515            Headline  Crime, Thriller & Adventure  \n",
       "72      959,496  Little, Brown Book      Autobiography: The Arts  \n",
       "73      956,114       HarperCollins   General & Literary Fiction  \n",
       "74      945,640          Transworld      Autobiography: The Arts  \n",
       "75      931,312          Transworld               Travel Writing  \n",
       "76      925,425             Penguin        Food & Drink: General  \n",
       "77      924,695       Pan Macmillan   General & Literary Fiction  \n",
       "78      906,968             Penguin  National & Regional Cuisine  \n",
       "79      905,086          Transworld               Fitness & Diet  \n",
       "80      890,847          Transworld               Travel Writing  \n",
       "81      869,671        Random House  Crime, Thriller & Adventure  \n",
       "82      869,659            Headline   General & Literary Fiction  \n",
       "83      862,602        Random House        Food & Drink: General  \n",
       "84      856,540          Transworld   General & Literary Fiction  \n",
       "85      845,858             Penguin   General & Literary Fiction  \n",
       "86      842,535       Pan Macmillan                Picture Books  \n",
       "87      828,215             Penguin   General & Literary Fiction  \n",
       "88      820,563  Hodder & Stoughton      Autobiography: The Arts  \n",
       "89      816,907          Transworld              Popular Science  \n",
       "90      816,585        D.C. Thomson           Children's Annuals  \n",
       "91      815,586             Penguin   General & Literary Fiction  \n",
       "92      814,370       Pan Macmillan   General & Literary Fiction  \n",
       "93      809,641          Transworld   General & Literary Fiction  \n",
       "94      808,900               Orion   General & Literary Fiction  \n",
       "95      807,311        Random House   General & Literary Fiction  \n",
       "96      794,201             Penguin        Food & Drink: General  \n",
       "97      792,187     Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507               Orion           Biography: General  \n",
       "99      791,095             Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.DataFrame()\n",
    "df['Book Name']=Book[:100]\n",
    "df['Author Name']=Author[:100]\n",
    "df['Volumes Sold']=Sold[:100]\n",
    "df['Publisher Name']=Publisher[:100]\n",
    "df['Genre']=Genre[:100]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 7. Scrape the details most watched tv series of all time from imdb.com."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://www.imdb.com/list/ls095964455/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Game of Thrones',\n",
       " 'Stranger Things',\n",
       " 'The Walking Dead',\n",
       " '13 Reasons Why',\n",
       " 'The 100',\n",
       " 'Orange Is the New Black',\n",
       " 'Riverdale',\n",
       " \"Grey's Anatomy\",\n",
       " 'The Flash',\n",
       " 'Arrow',\n",
       " 'Money Heist',\n",
       " 'The Big Bang Theory',\n",
       " 'Black Mirror',\n",
       " 'Sherlock',\n",
       " 'Vikings',\n",
       " 'Pretty Little Liars',\n",
       " 'The Vampire Diaries',\n",
       " 'American Horror Story',\n",
       " 'Breaking Bad',\n",
       " 'Lucifer',\n",
       " 'Supernatural',\n",
       " 'Prison Break',\n",
       " 'How to Get Away with Murder',\n",
       " 'Teen Wolf',\n",
       " 'The Simpsons',\n",
       " 'Once Upon a Time',\n",
       " 'Narcos',\n",
       " 'Daredevil',\n",
       " 'Friends',\n",
       " 'How I Met Your Mother',\n",
       " 'Suits',\n",
       " 'Mr. Robot',\n",
       " 'The Originals',\n",
       " 'Supergirl',\n",
       " 'Gossip Girl',\n",
       " 'Sense8',\n",
       " 'Gotham',\n",
       " 'Westworld',\n",
       " 'Jessica Jones',\n",
       " 'Modern Family',\n",
       " 'Rick and Morty',\n",
       " 'Shadowhunters',\n",
       " 'The End of the F***ing World',\n",
       " 'House of Cards',\n",
       " 'Dark',\n",
       " 'Elite',\n",
       " 'Sex Education',\n",
       " 'Shameless',\n",
       " 'New Girl',\n",
       " 'Agents of S.H.I.E.L.D.',\n",
       " 'You',\n",
       " 'Dexter',\n",
       " 'Fear the Walking Dead',\n",
       " 'Family Guy',\n",
       " 'The Blacklist',\n",
       " 'Lost',\n",
       " 'Peaky Blinders',\n",
       " 'House',\n",
       " 'Quantico',\n",
       " 'Orphan Black',\n",
       " 'Homeland',\n",
       " 'Blindspot',\n",
       " \"DC's Legends of Tomorrow\",\n",
       " \"The Handmaid's Tale\",\n",
       " 'Chilling Adventures of Sabrina',\n",
       " 'The Good Doctor',\n",
       " 'Jane the Virgin',\n",
       " 'Glee',\n",
       " 'South Park',\n",
       " 'Brooklyn Nine-Nine',\n",
       " 'Under the Dome',\n",
       " 'The Umbrella Academy',\n",
       " 'True Detective',\n",
       " 'The OA',\n",
       " 'Desperate Housewives',\n",
       " 'Better Call Saul',\n",
       " 'Bates Motel',\n",
       " 'The Punisher',\n",
       " 'Atypical',\n",
       " 'Dynasty',\n",
       " 'This Is Us',\n",
       " 'The Good Place',\n",
       " 'Iron Fist',\n",
       " 'The Rain',\n",
       " 'Mindhunter',\n",
       " 'Revenge',\n",
       " 'Luke Cage',\n",
       " 'Scandal',\n",
       " 'The Defenders',\n",
       " 'Big Little Lies',\n",
       " 'Insatiable',\n",
       " 'The Mentalist',\n",
       " 'The Crown',\n",
       " 'Chernobyl',\n",
       " 'iZombie',\n",
       " 'Reign',\n",
       " 'A Series of Unfortunate Events',\n",
       " 'Criminal Minds',\n",
       " 'Scream: The TV Series',\n",
       " 'The Haunting of Hill House']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape All Series name\n",
    "\n",
    "n = driver.find_elements(By.XPATH,\"//h3/a\")\n",
    "Name=[]\n",
    "\n",
    "for i in n:\n",
    "    Name.append(i.text)\n",
    "    \n",
    "Name    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(2011â€“2019)',\n",
       " '(2016â€“2025)',\n",
       " '(2010â€“2022)',\n",
       " '(2017â€“2020)',\n",
       " '(2014â€“2020)',\n",
       " '(2013â€“2019)',\n",
       " '(2017â€“2023)',\n",
       " '(2005â€“ )',\n",
       " '(2014â€“2023)',\n",
       " '(2012â€“2020)',\n",
       " '(2017â€“2021)',\n",
       " '(2007â€“2019)',\n",
       " '(2011â€“ )',\n",
       " '(2010â€“2017)',\n",
       " '(2013â€“2020)',\n",
       " '(2010â€“2017)',\n",
       " '(2009â€“2017)',\n",
       " '(2011â€“ )',\n",
       " '(2008â€“2013)',\n",
       " '(2016â€“2021)',\n",
       " '(2005â€“2020)',\n",
       " '(2005â€“2017)',\n",
       " '(2014â€“2020)',\n",
       " '(2011â€“2017)',\n",
       " '(1989â€“ )',\n",
       " '(2011â€“2018)',\n",
       " '(I) (2015â€“2017)',\n",
       " '(2015â€“2018)',\n",
       " '(1994â€“2004)',\n",
       " '(2005â€“2014)',\n",
       " '(2011â€“2019)',\n",
       " '(2015â€“2019)',\n",
       " '(2013â€“2018)',\n",
       " '(2015â€“2021)',\n",
       " '(2007â€“2012)',\n",
       " '(2015â€“2018)',\n",
       " '(2014â€“2019)',\n",
       " '(2016â€“2022)',\n",
       " '(2015â€“2019)',\n",
       " '(2009â€“2020)',\n",
       " '(2013â€“ )',\n",
       " '(2016â€“2019)',\n",
       " '(2017â€“2019)',\n",
       " '(2013â€“2018)',\n",
       " '(2017â€“2020)',\n",
       " '(2018â€“ )',\n",
       " '(2019â€“2023)',\n",
       " '(2011â€“2021)',\n",
       " '(2011â€“2018)',\n",
       " '(2013â€“2020)',\n",
       " '(2018â€“2024)',\n",
       " '(2006â€“2013)',\n",
       " '(2015â€“2023)',\n",
       " '(1999â€“ )',\n",
       " '(2013â€“2023)',\n",
       " '(2004â€“2010)',\n",
       " '(2013â€“2022)',\n",
       " '(2004â€“2012)',\n",
       " '(2015â€“2018)',\n",
       " '(2013â€“2017)',\n",
       " '(2011â€“2020)',\n",
       " '(2015â€“2020)',\n",
       " '(2016â€“2022)',\n",
       " '(2017â€“ )',\n",
       " '(2018â€“2020)',\n",
       " '(2017â€“ )',\n",
       " '(2014â€“2019)',\n",
       " '(2009â€“2015)',\n",
       " '(1997â€“ )',\n",
       " '(2013â€“2021)',\n",
       " '(2013â€“2015)',\n",
       " '(2019â€“2023)',\n",
       " '(2014â€“ )',\n",
       " '(2016â€“2019)',\n",
       " '(2004â€“2012)',\n",
       " '(2015â€“2022)',\n",
       " '(2013â€“2017)',\n",
       " '(2017â€“2019)',\n",
       " '(2017â€“2021)',\n",
       " '(2017â€“2022)',\n",
       " '(2016â€“2022)',\n",
       " '(2016â€“2020)',\n",
       " '(2017â€“2018)',\n",
       " '(2018â€“2020)',\n",
       " '(2017â€“2019)',\n",
       " '(2011â€“2015)',\n",
       " '(2016â€“2018)',\n",
       " '(2012â€“2018)',\n",
       " '(2017)',\n",
       " '(2017â€“2019)',\n",
       " '(2018â€“2019)',\n",
       " '(2008â€“2015)',\n",
       " '(2016â€“2023)',\n",
       " '(2019)',\n",
       " '(2015â€“2019)',\n",
       " '(2013â€“2017)',\n",
       " '(2017â€“2019)',\n",
       " '(2005â€“ )',\n",
       " '(2015â€“2019)',\n",
       " '(2018)']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape Year of span\n",
    "\n",
    "s = driver.find_elements(By.XPATH,\"//span[@class='lister-item-year text-muted unbold']\")\n",
    "Year=[]\n",
    "\n",
    "for i in s:\n",
    "    Year.append(i.text)\n",
    "    \n",
    "Year    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Action, Adventure, Drama',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama, Horror, Thriller',\n",
       " 'Drama, Mystery, Thriller',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Romance',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Romance',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Mystery, Romance',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama, Horror, Sci-Fi',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Crime, Drama, Fantasy',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Action, Crime, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Drama, Fantasy',\n",
       " 'Animation, Comedy',\n",
       " 'Adventure, Fantasy, Romance',\n",
       " 'Biography, Crime, Drama',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Romance',\n",
       " 'Comedy, Drama, Romance',\n",
       " 'Comedy, Drama',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Romance',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Crime, Drama',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Drama, Romance',\n",
       " 'Animation, Adventure, Comedy',\n",
       " 'Action, Drama, Fantasy',\n",
       " 'Adventure, Comedy, Crime',\n",
       " 'Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Crime, Drama, Thriller',\n",
       " 'Comedy, Drama',\n",
       " 'Comedy, Drama',\n",
       " 'Comedy, Romance',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Crime, Drama, Romance',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Horror, Sci-Fi',\n",
       " 'Animation, Comedy',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Adventure, Drama, Fantasy',\n",
       " 'Crime, Drama',\n",
       " 'Drama, Mystery',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Action, Crime, Drama',\n",
       " 'Action, Adventure, Drama',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Drama, Fantasy, Horror',\n",
       " 'Drama',\n",
       " 'Comedy',\n",
       " 'Comedy, Drama, Music',\n",
       " 'Animation, Comedy',\n",
       " 'Comedy, Crime',\n",
       " 'Drama, Mystery, Sci-Fi',\n",
       " 'Action, Adventure, Comedy',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Fantasy, Mystery',\n",
       " 'Comedy, Drama, Mystery',\n",
       " 'Crime, Drama',\n",
       " 'Drama, Horror, Mystery',\n",
       " 'Action, Crime, Drama',\n",
       " 'Comedy, Drama',\n",
       " 'Drama',\n",
       " 'Comedy, Drama, Romance',\n",
       " 'Comedy, Drama, Fantasy',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Drama, Sci-Fi, Thriller',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Drama, Mystery, Thriller',\n",
       " 'Action, Crime, Drama',\n",
       " 'Drama, Thriller',\n",
       " 'Action, Adventure, Crime',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Comedy, Drama, Thriller',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Biography, Drama, History',\n",
       " 'Drama, History, Thriller',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Drama',\n",
       " 'Adventure, Comedy, Drama',\n",
       " 'Crime, Drama, Mystery',\n",
       " 'Comedy, Crime, Drama',\n",
       " 'Drama, Horror, Mystery']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape Genre\n",
    "\n",
    "g = driver.find_elements(By.XPATH,\"//span[@class='genre']\")\n",
    "\n",
    "Genre=[]\n",
    "\n",
    "for i in g:\n",
    "    Genre.append(i.text)\n",
    "    \n",
    "Genre    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['57 min',\n",
       " '51 min',\n",
       " '44 min',\n",
       " '60 min',\n",
       " '43 min',\n",
       " '59 min',\n",
       " '45 min',\n",
       " '41 min',\n",
       " '43 min',\n",
       " '42 min',\n",
       " '70 min',\n",
       " '22 min',\n",
       " '60 min',\n",
       " '88 min',\n",
       " '44 min',\n",
       " '44 min',\n",
       " '43 min',\n",
       " '60 min',\n",
       " '49 min',\n",
       " '42 min',\n",
       " '44 min',\n",
       " '44 min',\n",
       " '43 min',\n",
       " '41 min',\n",
       " '22 min',\n",
       " '60 min',\n",
       " '49 min',\n",
       " '54 min',\n",
       " '22 min',\n",
       " '22 min',\n",
       " '44 min',\n",
       " '49 min',\n",
       " '45 min',\n",
       " '43 min',\n",
       " '42 min',\n",
       " '60 min',\n",
       " '42 min',\n",
       " '62 min',\n",
       " '56 min',\n",
       " '22 min',\n",
       " '23 min',\n",
       " '42 min',\n",
       " '25 min',\n",
       " '51 min',\n",
       " '60 min',\n",
       " '60 min',\n",
       " '45 min',\n",
       " '46 min',\n",
       " '22 min',\n",
       " '45 min',\n",
       " '45 min',\n",
       " '53 min',\n",
       " '44 min',\n",
       " '22 min',\n",
       " '43 min',\n",
       " '44 min',\n",
       " '60 min',\n",
       " '44 min',\n",
       " '42 min',\n",
       " '44 min',\n",
       " '55 min',\n",
       " '42 min',\n",
       " '42 min',\n",
       " '60 min',\n",
       " '60 min',\n",
       " '41 min',\n",
       " '60 min',\n",
       " '44 min',\n",
       " '22 min',\n",
       " '22 min',\n",
       " '43 min',\n",
       " '60 min',\n",
       " '55 min',\n",
       " '60 min',\n",
       " '45 min',\n",
       " '46 min',\n",
       " '45 min',\n",
       " '53 min',\n",
       " '30 min',\n",
       " '42 min',\n",
       " '45 min',\n",
       " '22 min',\n",
       " '55 min',\n",
       " '45 min',\n",
       " '60 min',\n",
       " '44 min',\n",
       " '55 min',\n",
       " '43 min',\n",
       " '50 min',\n",
       " '60 min',\n",
       " '45 min',\n",
       " '43 min',\n",
       " '58 min',\n",
       " '330 min',\n",
       " '42 min',\n",
       " '42 min',\n",
       " '50 min',\n",
       " '42 min',\n",
       " '45 min',\n",
       " '572 min']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape runtime\n",
    "\n",
    "t = driver.find_elements(By.XPATH,\"//span[@class='runtime']\")\n",
    "\n",
    "Time=[]\n",
    "\n",
    "for i in t:\n",
    "    Time.append(i.text)\n",
    "    \n",
    "Time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['9.2',\n",
       " '8.7',\n",
       " '8.1',\n",
       " '7.5',\n",
       " '7.6',\n",
       " '8',\n",
       " '6.5',\n",
       " '7.6',\n",
       " '7.5',\n",
       " '7.5',\n",
       " '8.2',\n",
       " '8.2',\n",
       " '8.7',\n",
       " '9.1',\n",
       " '8.5',\n",
       " '7.4',\n",
       " '7.7',\n",
       " '8',\n",
       " '9.5',\n",
       " '8.1',\n",
       " '8.4',\n",
       " '8.3',\n",
       " '8.1',\n",
       " '7.7',\n",
       " '8.7',\n",
       " '7.7',\n",
       " '8.8',\n",
       " '8.6',\n",
       " '8.9',\n",
       " '8.3',\n",
       " '8.4',\n",
       " '8.5',\n",
       " '8.3',\n",
       " '6.2',\n",
       " '7.5',\n",
       " '8.2',\n",
       " '7.8',\n",
       " '8.5',\n",
       " '7.9',\n",
       " '8.5',\n",
       " '9.1',\n",
       " '6.5',\n",
       " '8',\n",
       " '8.7',\n",
       " '8.7',\n",
       " '7.3',\n",
       " '8.3',\n",
       " '8.5',\n",
       " '7.8',\n",
       " '7.5',\n",
       " '7.7',\n",
       " '8.7',\n",
       " '6.8',\n",
       " '8.2',\n",
       " '8',\n",
       " '8.3',\n",
       " '8.8',\n",
       " '8.7',\n",
       " '6.7',\n",
       " '8.3',\n",
       " '8.3',\n",
       " '7.3',\n",
       " '6.8',\n",
       " '8.4',\n",
       " '7.4',\n",
       " '8',\n",
       " '7.9',\n",
       " '6.8',\n",
       " '8.7',\n",
       " '8.4',\n",
       " '6.5',\n",
       " '7.9',\n",
       " '8.9',\n",
       " '7.8',\n",
       " '7.6',\n",
       " '9',\n",
       " '8.1',\n",
       " '8.5',\n",
       " '8.2',\n",
       " '7.3',\n",
       " '8.7',\n",
       " '8.2',\n",
       " '6.4',\n",
       " '6.3',\n",
       " '8.6',\n",
       " '7.8',\n",
       " '7.3',\n",
       " '7.7',\n",
       " '7.2',\n",
       " '8.5',\n",
       " '6.5',\n",
       " '8.2',\n",
       " '8.6',\n",
       " '9.3',\n",
       " '7.8',\n",
       " '7.5',\n",
       " '7.8',\n",
       " '8.1',\n",
       " '7',\n",
       " '8.6']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape rating\n",
    "\n",
    "r = driver.find_elements(By.XPATH,\"//div[@id='main']/div/div[3]/div[3]/div/div[2]/div/div/span[2]\")\n",
    "\n",
    "#//*[@id=\"main\"]/div/div[3]/div[3]/div[3]/div[2]/div[1]/div[1]/span[2]\n",
    "\n",
    "Ratings=[]\n",
    "\n",
    "for i in r:\n",
    "    Ratings.append(i.text)\n",
    "    \n",
    "Ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2,203,091',\n",
       " '1,274,894',\n",
       " '1,045,366',\n",
       " '307,232',\n",
       " '266,340',\n",
       " '313,766',\n",
       " '151,589',\n",
       " '328,407',\n",
       " '363,077',\n",
       " '440,949',\n",
       " '507,681',\n",
       " '840,761',\n",
       " '610,591',\n",
       " '966,359',\n",
       " '561,477',\n",
       " '174,383',\n",
       " '338,055',\n",
       " '331,537',\n",
       " '2,035,944',\n",
       " '342,890',\n",
       " '466,681',\n",
       " '561,965',\n",
       " '160,879',\n",
       " '158,607',\n",
       " '423,920',\n",
       " '232,051',\n",
       " '451,865',\n",
       " '460,618',\n",
       " '1,045,044',\n",
       " '710,655',\n",
       " '449,141',\n",
       " '405,607',\n",
       " '143,296',\n",
       " '127,769',\n",
       " '185,510',\n",
       " '159,637',\n",
       " '237,022',\n",
       " '520,757',\n",
       " '221,888',\n",
       " '461,312',\n",
       " '567,101',\n",
       " '67,974',\n",
       " '209,122',\n",
       " '520,321',\n",
       " '420,308',\n",
       " '86,654',\n",
       " '312,012',\n",
       " '264,177',\n",
       " '237,887',\n",
       " '222,739',\n",
       " '284,469',\n",
       " '746,741',\n",
       " '137,971',\n",
       " '355,095',\n",
       " '270,984',\n",
       " '577,382',\n",
       " '605,975',\n",
       " '489,437',\n",
       " '62,840',\n",
       " '114,614',\n",
       " '353,378',\n",
       " '77,292',\n",
       " '108,409',\n",
       " '250,145',\n",
       " '103,452',\n",
       " '107,304',\n",
       " '56,172',\n",
       " '153,073',\n",
       " '394,492',\n",
       " '342,185',\n",
       " '110,235',\n",
       " '263,480',\n",
       " '608,140',\n",
       " '110,602',\n",
       " '135,316',\n",
       " '603,974',\n",
       " '113,625',\n",
       " '253,932',\n",
       " '98,814',\n",
       " '24,160',\n",
       " '152,244',\n",
       " '178,254',\n",
       " '136,518',\n",
       " '40,115',\n",
       " '315,140',\n",
       " '123,024',\n",
       " '136,595',\n",
       " '77,814',\n",
       " '113,387',\n",
       " '215,116',\n",
       " '31,290',\n",
       " '194,243',\n",
       " '234,117',\n",
       " '820,001',\n",
       " '72,044',\n",
       " '52,701',\n",
       " '64,753',\n",
       " '210,952',\n",
       " '43,879',\n",
       " '265,717']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape votes\n",
    "\n",
    "v = driver.find_elements(By.XPATH,\"//span[@name='nv']\")\n",
    "\n",
    "Votes=[]\n",
    "\n",
    "for i in v:\n",
    "    Votes.append(i.text)\n",
    "    \n",
    "Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 100 100 100 100 100\n"
     ]
    }
   ],
   "source": [
    "print(len(Name),len(Year),len(Genre),len(Time),len(Ratings),len(Votes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011â€“2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,203,091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016â€“2025)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,274,894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010â€“2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>1,045,366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017â€“2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>307,232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014â€“2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>266,340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Orange Is the New Black</td>\n",
       "      <td>(2013â€“2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>59 min</td>\n",
       "      <td>8</td>\n",
       "      <td>313,766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Riverdale</td>\n",
       "      <td>(2017â€“2023)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>45 min</td>\n",
       "      <td>6.5</td>\n",
       "      <td>151,589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Grey's Anatomy</td>\n",
       "      <td>(2005â€“ )</td>\n",
       "      <td>Drama, Romance</td>\n",
       "      <td>41 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>328,407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>The Flash</td>\n",
       "      <td>(2014â€“2023)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>363,077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Arrow</td>\n",
       "      <td>(2012â€“2020)</td>\n",
       "      <td>Action, Adventure, Crime</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>440,949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Money Heist</td>\n",
       "      <td>(2017â€“2021)</td>\n",
       "      <td>Action, Crime, Drama</td>\n",
       "      <td>70 min</td>\n",
       "      <td>8.2</td>\n",
       "      <td>507,681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>The Big Bang Theory</td>\n",
       "      <td>(2007â€“2019)</td>\n",
       "      <td>Comedy, Romance</td>\n",
       "      <td>22 min</td>\n",
       "      <td>8.2</td>\n",
       "      <td>840,761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Black Mirror</td>\n",
       "      <td>(2011â€“ )</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>60 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>610,591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sherlock</td>\n",
       "      <td>(2010â€“2017)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>88 min</td>\n",
       "      <td>9.1</td>\n",
       "      <td>966,359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Vikings</td>\n",
       "      <td>(2013â€“2020)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.5</td>\n",
       "      <td>561,477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Pretty Little Liars</td>\n",
       "      <td>(2010â€“2017)</td>\n",
       "      <td>Drama, Mystery, Romance</td>\n",
       "      <td>44 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>174,383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>The Vampire Diaries</td>\n",
       "      <td>(2009â€“2017)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.7</td>\n",
       "      <td>338,055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>American Horror Story</td>\n",
       "      <td>(2011â€“ )</td>\n",
       "      <td>Drama, Horror, Sci-Fi</td>\n",
       "      <td>60 min</td>\n",
       "      <td>8</td>\n",
       "      <td>331,537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Breaking Bad</td>\n",
       "      <td>(2008â€“2013)</td>\n",
       "      <td>Crime, Drama, Thriller</td>\n",
       "      <td>49 min</td>\n",
       "      <td>9.5</td>\n",
       "      <td>2,035,944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Lucifer</td>\n",
       "      <td>(2016â€“2021)</td>\n",
       "      <td>Crime, Drama, Fantasy</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>342,890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Supernatural</td>\n",
       "      <td>(2005â€“2020)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.4</td>\n",
       "      <td>466,681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Prison Break</td>\n",
       "      <td>(2005â€“2017)</td>\n",
       "      <td>Action, Crime, Drama</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.3</td>\n",
       "      <td>561,965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>How to Get Away with Murder</td>\n",
       "      <td>(2014â€“2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>43 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>160,879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Teen Wolf</td>\n",
       "      <td>(2011â€“2017)</td>\n",
       "      <td>Action, Drama, Fantasy</td>\n",
       "      <td>41 min</td>\n",
       "      <td>7.7</td>\n",
       "      <td>158,607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>The Simpsons</td>\n",
       "      <td>(1989â€“ )</td>\n",
       "      <td>Animation, Comedy</td>\n",
       "      <td>22 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>423,920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Once Upon a Time</td>\n",
       "      <td>(2011â€“2018)</td>\n",
       "      <td>Adventure, Fantasy, Romance</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.7</td>\n",
       "      <td>232,051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Narcos</td>\n",
       "      <td>(I) (2015â€“2017)</td>\n",
       "      <td>Biography, Crime, Drama</td>\n",
       "      <td>49 min</td>\n",
       "      <td>8.8</td>\n",
       "      <td>451,865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Daredevil</td>\n",
       "      <td>(2015â€“2018)</td>\n",
       "      <td>Action, Crime, Drama</td>\n",
       "      <td>54 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>460,618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Friends</td>\n",
       "      <td>(1994â€“2004)</td>\n",
       "      <td>Comedy, Romance</td>\n",
       "      <td>22 min</td>\n",
       "      <td>8.9</td>\n",
       "      <td>1,045,044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>How I Met Your Mother</td>\n",
       "      <td>(2005â€“2014)</td>\n",
       "      <td>Comedy, Drama, Romance</td>\n",
       "      <td>22 min</td>\n",
       "      <td>8.3</td>\n",
       "      <td>710,655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Under the Dome</td>\n",
       "      <td>(2013â€“2015)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>6.5</td>\n",
       "      <td>110,235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>The Umbrella Academy</td>\n",
       "      <td>(2019â€“2023)</td>\n",
       "      <td>Action, Adventure, Comedy</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.9</td>\n",
       "      <td>263,480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>True Detective</td>\n",
       "      <td>(2014â€“ )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>55 min</td>\n",
       "      <td>8.9</td>\n",
       "      <td>608,140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>The OA</td>\n",
       "      <td>(2016â€“2019)</td>\n",
       "      <td>Drama, Fantasy, Mystery</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>110,602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Desperate Housewives</td>\n",
       "      <td>(2004â€“2012)</td>\n",
       "      <td>Comedy, Drama, Mystery</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>135,316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Better Call Saul</td>\n",
       "      <td>(2015â€“2022)</td>\n",
       "      <td>Crime, Drama</td>\n",
       "      <td>46 min</td>\n",
       "      <td>9</td>\n",
       "      <td>603,974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Bates Motel</td>\n",
       "      <td>(2013â€“2017)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>45 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>113,625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>The Punisher</td>\n",
       "      <td>(2017â€“2019)</td>\n",
       "      <td>Action, Crime, Drama</td>\n",
       "      <td>53 min</td>\n",
       "      <td>8.5</td>\n",
       "      <td>253,932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Atypical</td>\n",
       "      <td>(2017â€“2021)</td>\n",
       "      <td>Comedy, Drama</td>\n",
       "      <td>30 min</td>\n",
       "      <td>8.2</td>\n",
       "      <td>98,814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Dynasty</td>\n",
       "      <td>(2017â€“2022)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.3</td>\n",
       "      <td>24,160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>This Is Us</td>\n",
       "      <td>(2016â€“2022)</td>\n",
       "      <td>Comedy, Drama, Romance</td>\n",
       "      <td>45 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>152,244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>The Good Place</td>\n",
       "      <td>(2016â€“2020)</td>\n",
       "      <td>Comedy, Drama, Fantasy</td>\n",
       "      <td>22 min</td>\n",
       "      <td>8.2</td>\n",
       "      <td>178,254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Iron Fist</td>\n",
       "      <td>(2017â€“2018)</td>\n",
       "      <td>Action, Adventure, Crime</td>\n",
       "      <td>55 min</td>\n",
       "      <td>6.4</td>\n",
       "      <td>136,518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>The Rain</td>\n",
       "      <td>(2018â€“2020)</td>\n",
       "      <td>Drama, Sci-Fi, Thriller</td>\n",
       "      <td>45 min</td>\n",
       "      <td>6.3</td>\n",
       "      <td>40,115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Mindhunter</td>\n",
       "      <td>(2017â€“2019)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>60 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>315,140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>Revenge</td>\n",
       "      <td>(2011â€“2015)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>123,024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>Luke Cage</td>\n",
       "      <td>(2016â€“2018)</td>\n",
       "      <td>Action, Crime, Drama</td>\n",
       "      <td>55 min</td>\n",
       "      <td>7.3</td>\n",
       "      <td>136,595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>Scandal</td>\n",
       "      <td>(2012â€“2018)</td>\n",
       "      <td>Drama, Thriller</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.7</td>\n",
       "      <td>77,814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>The Defenders</td>\n",
       "      <td>(2017)</td>\n",
       "      <td>Action, Adventure, Crime</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.2</td>\n",
       "      <td>113,387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Big Little Lies</td>\n",
       "      <td>(2017â€“2019)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>60 min</td>\n",
       "      <td>8.5</td>\n",
       "      <td>215,116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Insatiable</td>\n",
       "      <td>(2018â€“2019)</td>\n",
       "      <td>Comedy, Drama, Thriller</td>\n",
       "      <td>45 min</td>\n",
       "      <td>6.5</td>\n",
       "      <td>31,290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>The Mentalist</td>\n",
       "      <td>(2008â€“2015)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>43 min</td>\n",
       "      <td>8.2</td>\n",
       "      <td>194,243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>The Crown</td>\n",
       "      <td>(2016â€“2023)</td>\n",
       "      <td>Biography, Drama, History</td>\n",
       "      <td>58 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>234,117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>Chernobyl</td>\n",
       "      <td>(2019)</td>\n",
       "      <td>Drama, History, Thriller</td>\n",
       "      <td>330 min</td>\n",
       "      <td>9.3</td>\n",
       "      <td>820,001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>iZombie</td>\n",
       "      <td>(2015â€“2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>72,044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013â€“2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>52,701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017â€“2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>64,753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005â€“ )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>210,952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015â€“2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7</td>\n",
       "      <td>43,879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>265,717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name             Year  \\\n",
       "0                  Game of Thrones      (2011â€“2019)   \n",
       "1                  Stranger Things      (2016â€“2025)   \n",
       "2                 The Walking Dead      (2010â€“2022)   \n",
       "3                   13 Reasons Why      (2017â€“2020)   \n",
       "4                          The 100      (2014â€“2020)   \n",
       "5          Orange Is the New Black      (2013â€“2019)   \n",
       "6                        Riverdale      (2017â€“2023)   \n",
       "7                   Grey's Anatomy         (2005â€“ )   \n",
       "8                        The Flash      (2014â€“2023)   \n",
       "9                            Arrow      (2012â€“2020)   \n",
       "10                     Money Heist      (2017â€“2021)   \n",
       "11             The Big Bang Theory      (2007â€“2019)   \n",
       "12                    Black Mirror         (2011â€“ )   \n",
       "13                        Sherlock      (2010â€“2017)   \n",
       "14                         Vikings      (2013â€“2020)   \n",
       "15             Pretty Little Liars      (2010â€“2017)   \n",
       "16             The Vampire Diaries      (2009â€“2017)   \n",
       "17           American Horror Story         (2011â€“ )   \n",
       "18                    Breaking Bad      (2008â€“2013)   \n",
       "19                         Lucifer      (2016â€“2021)   \n",
       "20                    Supernatural      (2005â€“2020)   \n",
       "21                    Prison Break      (2005â€“2017)   \n",
       "22     How to Get Away with Murder      (2014â€“2020)   \n",
       "23                       Teen Wolf      (2011â€“2017)   \n",
       "24                    The Simpsons         (1989â€“ )   \n",
       "25                Once Upon a Time      (2011â€“2018)   \n",
       "26                          Narcos  (I) (2015â€“2017)   \n",
       "27                       Daredevil      (2015â€“2018)   \n",
       "28                         Friends      (1994â€“2004)   \n",
       "29           How I Met Your Mother      (2005â€“2014)   \n",
       "..                             ...              ...   \n",
       "70                  Under the Dome      (2013â€“2015)   \n",
       "71            The Umbrella Academy      (2019â€“2023)   \n",
       "72                  True Detective         (2014â€“ )   \n",
       "73                          The OA      (2016â€“2019)   \n",
       "74            Desperate Housewives      (2004â€“2012)   \n",
       "75                Better Call Saul      (2015â€“2022)   \n",
       "76                     Bates Motel      (2013â€“2017)   \n",
       "77                    The Punisher      (2017â€“2019)   \n",
       "78                        Atypical      (2017â€“2021)   \n",
       "79                         Dynasty      (2017â€“2022)   \n",
       "80                      This Is Us      (2016â€“2022)   \n",
       "81                  The Good Place      (2016â€“2020)   \n",
       "82                       Iron Fist      (2017â€“2018)   \n",
       "83                        The Rain      (2018â€“2020)   \n",
       "84                      Mindhunter      (2017â€“2019)   \n",
       "85                         Revenge      (2011â€“2015)   \n",
       "86                       Luke Cage      (2016â€“2018)   \n",
       "87                         Scandal      (2012â€“2018)   \n",
       "88                   The Defenders           (2017)   \n",
       "89                 Big Little Lies      (2017â€“2019)   \n",
       "90                      Insatiable      (2018â€“2019)   \n",
       "91                   The Mentalist      (2008â€“2015)   \n",
       "92                       The Crown      (2016â€“2023)   \n",
       "93                       Chernobyl           (2019)   \n",
       "94                         iZombie      (2015â€“2019)   \n",
       "95                           Reign      (2013â€“2017)   \n",
       "96  A Series of Unfortunate Events      (2017â€“2019)   \n",
       "97                  Criminal Minds         (2005â€“ )   \n",
       "98           Scream: The TV Series      (2015â€“2019)   \n",
       "99      The Haunting of Hill House           (2018)   \n",
       "\n",
       "                          Genre     Time Ratings      Votes  \n",
       "0      Action, Adventure, Drama   57 min     9.2  2,203,091  \n",
       "1        Drama, Fantasy, Horror   51 min     8.7  1,274,894  \n",
       "2       Drama, Horror, Thriller   44 min     8.1  1,045,366  \n",
       "3      Drama, Mystery, Thriller   60 min     7.5    307,232  \n",
       "4        Drama, Mystery, Sci-Fi   43 min     7.6    266,340  \n",
       "5          Comedy, Crime, Drama   59 min       8    313,766  \n",
       "6         Crime, Drama, Mystery   45 min     6.5    151,589  \n",
       "7                Drama, Romance   41 min     7.6    328,407  \n",
       "8      Action, Adventure, Drama   43 min     7.5    363,077  \n",
       "9      Action, Adventure, Crime   42 min     7.5    440,949  \n",
       "10         Action, Crime, Drama   70 min     8.2    507,681  \n",
       "11              Comedy, Romance   22 min     8.2    840,761  \n",
       "12       Drama, Mystery, Sci-Fi   60 min     8.7    610,591  \n",
       "13        Crime, Drama, Mystery   88 min     9.1    966,359  \n",
       "14     Action, Adventure, Drama   44 min     8.5    561,477  \n",
       "15      Drama, Mystery, Romance   44 min     7.4    174,383  \n",
       "16       Drama, Fantasy, Horror   43 min     7.7    338,055  \n",
       "17        Drama, Horror, Sci-Fi   60 min       8    331,537  \n",
       "18       Crime, Drama, Thriller   49 min     9.5  2,035,944  \n",
       "19        Crime, Drama, Fantasy   42 min     8.1    342,890  \n",
       "20       Drama, Fantasy, Horror   44 min     8.4    466,681  \n",
       "21         Action, Crime, Drama   44 min     8.3    561,965  \n",
       "22        Crime, Drama, Mystery   43 min     8.1    160,879  \n",
       "23       Action, Drama, Fantasy   41 min     7.7    158,607  \n",
       "24            Animation, Comedy   22 min     8.7    423,920  \n",
       "25  Adventure, Fantasy, Romance   60 min     7.7    232,051  \n",
       "26      Biography, Crime, Drama   49 min     8.8    451,865  \n",
       "27         Action, Crime, Drama   54 min     8.6    460,618  \n",
       "28              Comedy, Romance   22 min     8.9  1,045,044  \n",
       "29       Comedy, Drama, Romance   22 min     8.3    710,655  \n",
       "..                          ...      ...     ...        ...  \n",
       "70       Drama, Mystery, Sci-Fi   43 min     6.5    110,235  \n",
       "71    Action, Adventure, Comedy   60 min     7.9    263,480  \n",
       "72        Crime, Drama, Mystery   55 min     8.9    608,140  \n",
       "73      Drama, Fantasy, Mystery   60 min     7.8    110,602  \n",
       "74       Comedy, Drama, Mystery   45 min     7.6    135,316  \n",
       "75                 Crime, Drama   46 min       9    603,974  \n",
       "76       Drama, Horror, Mystery   45 min     8.1    113,625  \n",
       "77         Action, Crime, Drama   53 min     8.5    253,932  \n",
       "78                Comedy, Drama   30 min     8.2     98,814  \n",
       "79                        Drama   42 min     7.3     24,160  \n",
       "80       Comedy, Drama, Romance   45 min     8.7    152,244  \n",
       "81       Comedy, Drama, Fantasy   22 min     8.2    178,254  \n",
       "82     Action, Adventure, Crime   55 min     6.4    136,518  \n",
       "83      Drama, Sci-Fi, Thriller   45 min     6.3     40,115  \n",
       "84        Crime, Drama, Mystery   60 min     8.6    315,140  \n",
       "85     Drama, Mystery, Thriller   44 min     7.8    123,024  \n",
       "86         Action, Crime, Drama   55 min     7.3    136,595  \n",
       "87              Drama, Thriller   43 min     7.7     77,814  \n",
       "88     Action, Adventure, Crime   50 min     7.2    113,387  \n",
       "89        Crime, Drama, Mystery   60 min     8.5    215,116  \n",
       "90      Comedy, Drama, Thriller   45 min     6.5     31,290  \n",
       "91        Crime, Drama, Mystery   43 min     8.2    194,243  \n",
       "92    Biography, Drama, History   58 min     8.6    234,117  \n",
       "93     Drama, History, Thriller  330 min     9.3    820,001  \n",
       "94         Comedy, Crime, Drama   42 min     7.8     72,044  \n",
       "95                        Drama   42 min     7.5     52,701  \n",
       "96     Adventure, Comedy, Drama   50 min     7.8     64,753  \n",
       "97        Crime, Drama, Mystery   42 min     8.1    210,952  \n",
       "98         Comedy, Crime, Drama   45 min       7     43,879  \n",
       "99       Drama, Horror, Mystery  572 min     8.6    265,717  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.DataFrame()\n",
    "df['Name']=Name[:100]\n",
    "df['Year']=Year[:100]\n",
    "df['Genre']=Genre[:100]\n",
    "df['Time']=Time[:100]\n",
    "df['Ratings']=Ratings[:100]\n",
    "df['Votes']=Votes[:100]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 8 Details of Datasets from UCI machine learning repositories. Url = https://archive.ics.uci.edu/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://archive.ics.uci.edu/'\n",
    "driver.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.maximize_window()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = driver.find_element(By.XPATH,\"/html/body/div/div[1]/div[1]/header/nav/ul/li[1]/a\")\n",
    "d.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#m = driver.find_element(By.XPATH,\"/html/body/div/div[1]/div[1]/main/div/div[2]/div[3]/label/select\")\n",
    "#m.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Iris',\n",
       " 'Heart Disease',\n",
       " 'Adult',\n",
       " 'Dry Bean Dataset',\n",
       " 'Diabetes',\n",
       " 'Wine',\n",
       " 'Breast Cancer Wisconsin (Diagnostic)',\n",
       " 'Car Evaluation',\n",
       " 'Rice (Cammeo and Osmancik)',\n",
       " 'Mushroom']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape Dataset name\n",
    "\n",
    "n = driver.find_elements(By.XPATH,\"//h2/a\")\n",
    "\n",
    "Dataset=[]\n",
    "\n",
    "for i in n[:10]:\n",
    "    Dataset.append(i.text)\n",
    "    \n",
    "Dataset    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tabular',\n",
       " 'Multivariate',\n",
       " 'Multivariate',\n",
       " 'Multivariate',\n",
       " '',\n",
       " 'Tabular',\n",
       " 'Multivariate',\n",
       " 'Multivariate',\n",
       " 'Multivariate',\n",
       " 'Multivariate']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape Data type\n",
    "\n",
    "d = driver.find_elements(By.XPATH,\"//div/div[2]/span\")\n",
    "\n",
    "Data=[]\n",
    "\n",
    "for i in d[:10]:\n",
    "    Data.append(i.text)\n",
    "    \n",
    "Data    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Classification',\n",
       " 'Classification',\n",
       " 'Classification',\n",
       " 'Classification',\n",
       " '',\n",
       " 'Classification',\n",
       " 'Classification',\n",
       " 'Classification',\n",
       " 'Classification',\n",
       " 'Classification']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape Task\n",
    "\n",
    "t = driver.find_elements(By.XPATH,\"//div/div[1]/span\")\n",
    "\n",
    "Task=[]\n",
    "\n",
    "for i in t[:10]:\n",
    "    Task.append(i.text)\n",
    "    \n",
    "Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['150 Instances',\n",
       " '303 Instances',\n",
       " '48.84K Instances',\n",
       " '13.61K Instances',\n",
       " '',\n",
       " '178 Instances',\n",
       " '569 Instances',\n",
       " '1.73K Instances',\n",
       " '3.81K Instances',\n",
       " '8.12K Instances']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape Instances\n",
    "\n",
    "ins = driver.find_elements(By.XPATH,\"//div/div[3]/span\")\n",
    "\n",
    "Instances=[]\n",
    "\n",
    "for i in ins[:10]:\n",
    "    Instances.append(i.text)\n",
    "    \n",
    "Instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4 Features',\n",
       " '13 Features',\n",
       " '14 Features',\n",
       " '16 Features',\n",
       " '20 Features',\n",
       " '13 Features',\n",
       " '30 Features',\n",
       " '6 Features',\n",
       " '8 Features',\n",
       " '22 Features']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape Attribute\n",
    "\n",
    "at = driver.find_elements(By.XPATH,\"//div/div[4]/span\")\n",
    "\n",
    "Attribute=[]\n",
    "\n",
    "for i in at[:10]:\n",
    "    Attribute.append(i.text)\n",
    "    \n",
    "Attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scrape Year\n",
    "\n",
    "yr = driver.find_elements(By.XPATH,\"/html/body/div/div[1]/div[1]/main/div/div[2]/div[2]/div[1]/div[2]/div/table/tbody/tr/td[3]\") \n",
    "Year=[]\n",
    "\n",
    "for i in yr:\n",
    "    Year.append(i.text)\n",
    "    \n",
    "Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(Dataset),len(Data),len(Task),len(Instances))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Instances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Iris</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>150 Instances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Heart Disease</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>303 Instances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>48.84K Instances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dry Bean Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>13.61K Instances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Diabetes</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wine</td>\n",
       "      <td>Tabular</td>\n",
       "      <td>Classification</td>\n",
       "      <td>178 Instances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>569 Instances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Car Evaluation</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>1.73K Instances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Rice (Cammeo and Osmancik)</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>3.81K Instances</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mushroom</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>8.12K Instances</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Dataset Name     Data Type            Task  \\\n",
       "0                                  Iris       Tabular  Classification   \n",
       "1                         Heart Disease  Multivariate  Classification   \n",
       "2                                 Adult  Multivariate  Classification   \n",
       "3                      Dry Bean Dataset  Multivariate  Classification   \n",
       "4                              Diabetes                                 \n",
       "5                                  Wine       Tabular  Classification   \n",
       "6  Breast Cancer Wisconsin (Diagnostic)  Multivariate  Classification   \n",
       "7                        Car Evaluation  Multivariate  Classification   \n",
       "8            Rice (Cammeo and Osmancik)  Multivariate  Classification   \n",
       "9                              Mushroom  Multivariate  Classification   \n",
       "\n",
       "          Instances  \n",
       "0     150 Instances  \n",
       "1     303 Instances  \n",
       "2  48.84K Instances  \n",
       "3  13.61K Instances  \n",
       "4                    \n",
       "5     178 Instances  \n",
       "6     569 Instances  \n",
       "7   1.73K Instances  \n",
       "8   3.81K Instances  \n",
       "9   8.12K Instances  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating DataFrame\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['Dataset Name']=Dataset[:10]\n",
    "df['Data Type']=Data[:10]\n",
    "df['Task']=Task[:10]\n",
    "df['Instances']=Instances[:10]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
